
     <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" 
     "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"> 
     <html xmlns="http://www.w3.org/1999/xhtml"> 
     <head> 
     <title>Models of the Information Seeking Process (Ch 3) | Search User Interfaces | Marti Hearst | Cambridge University Press 2009</title><meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" /> <meta name="description"content="Full text content of the book Search User Interfaces, written by Marti Hearst and published by Cambridge University Press, 2009.  Chapter 3: Models of the Information Seeking Process" /><link href="css/sui.css" rel="stylesheet" type="text/css" media="all" /><link rel="shortcut icon" href="images/favicon.ico" /><script language="JavaScript" src="js/fix.js" type="text/JavaScript"></script><script language="JavaScript" src="js/qTip.js" type="text/JavaScript"></script>
     <script language="JavaScript" type="text/javascript" src="js/jquery.min.js"></script>
     <script language="JavaScript" type="text/javascript" src="js/slimbox2.js"></script>
     <link rel="stylesheet" href="css/slimbox2.css" type="text/css" media="screen" />
      <!-- suggest script -->
        <style type="text/css">@import url("sphider/include/js_suggest/SuggestFramework.css");</style>
        <script language="JavaScript" type="text/javascript" src="sphider/include/js_suggest/SuggestFramework.js"></script>
        <script language="JavaScript" type="text/javascript">AddOnload(initializeSuggestFramework);</script>
      <!-- /suggest script -->
     </head>
     <body>
     <div id="container">
       <div id="header">
       <h1><a href="http://www.searchuserinterfaces.com/">Search User Interfaces</a></h1>
     <div id="subtitle">
      Marti Hearst | Cambridge University Press | 2009
      </div>
        </div><!-- div header -->
            <div id="navmenu">
       <a href="http://searchuserinterfaces.com/">  Home </a>
       <a href="http://searchuserinterfaces.com/blog/">  Blog  </a>
          <a href="http://searchuserinterfaces.com/book/">  Book  </a>
       </div><!-- div navmenu -->
       <div id="maincol">  <div class="col"><div class="chapter" id="chapter_3"><div class="notice">From the book <i>Search User Interfaces</i>, published by Cambridge University Press.  Copyright &copy; 2009 by Marti A. Hearst.</div><h1>Ch. 3: Models of the Information Seeking Process</h1>
<p>
<div id="index_information seeking_1"></div>
<p>
In order to design successful search user interfaces, it is necessary to understand the human information seeking process, including the strategies people employ when engaged in search. Numerous theoretical treatments have been proposed to characterize this complex cognitive process (<a href="sui_references.html#belkin1982air" title="N.J. Belkin, R.N.
  Oddy, and H.M. Brooks.
ASK for information retrieval: Part I. Background and theory.
<i>Journal of Documentation</i>, 38(2):61&ndash;71, 1982.">Belkin et&nbsp;al., 1982</a>, <a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991."> Kuhlthau, 1991</a>, <a href="sui_references.html#marchionini95" title="Gary Marchionini.
<i>Information Seeking in Electronic Environments</i>.
Cambridge University Press, 1995."> Marchionini, 1995</a>, <a href="sui_references.html#saracevic1997smi" title="T.&nbsp;Saracevic.
The stratified model of information retrieval interaction: Extension and
  applications.
<i>Proceedings of the American Society for Information Science</i>,
  34(2):313&ndash;27, 1997."> Saracevic, 1997</a>, <a href="sui_references.html#sutcliffe1998" title="A.G.
  Sutcliffe and M.&nbsp;Ennis.
Towards a cognitive theory of information retrieval.
<i>Interacting with Computers</i>, 10:321&ndash;351, 1998."> Sutcliffe and Ennis, 1998</a>, <a href="sui_references.html#jarvelin2004isr" title="K.&nbsp;Jarvelin and P.&nbsp;Ingwersen.
Information seeking research needs extension towards tasks and technology.
<i>Information Research</i>, 10(1):10&ndash;1, 2004."> Jarvelin and Ingwersen,   2004</a>). This chapter presents the most commonly discussed theoretical models of the search process: the standard model, the cognitive model, the dynamic model, search as a sequence of stages, search as a strategic process, and sensemaking. The chapter concludes with a discussion of information needs, including methods for inferring information needs from their expression as queries. <p>
<div class="section" id="section_3.1"><h2>3.1: The Standard Model of Information Seeking</h2>
<p>
<p>
Many accounts of the information seeking process assume an interaction cycle consisting of identifying an information need, followed by the activities of query specification, examination of retrieval results, and if needed, reformulation of the query, repeating the cycle until a satisfactory result set is found (<a href="sui_references.html#salton89" title="Gerard Salton.
<i>Automatic text processing: the transformation, analysis, and retrieval of
  information by computer</i>.
Addison-Wesley, Reading, MA, 1989.">Salton, 1989</a>, <a href="sui_references.html#shneiderman98" title="B.&nbsp;Shneiderman, D.&nbsp;Byrd, and W.B. Croft.
Sorting out searching: A user-interface framework for text searches.
<i>Communications of the ACM</i>, 41(4):95&ndash;98, 1998."> Shneiderman et&nbsp;al.,   1998</a>). As <a href="sui_references.html#marchionini1989iss" title="G.&nbsp;Marchionini.
Information-seeking strategies of novices using a full-text electronic
  encyclopedia.
<i>Journal of the American Society for Information Science</i>,
  40(1):54&ndash;66, 1989.">Marchionini,   1989</a> puts it: <p>
<blockquote>
&#8220;Information-seeking is a special case of problem solving. It includes recognizing and interpreting the information problem, establishing a plan of search, conducting the search, evaluating the results, and if necessary, iterating through the process again.&#8221; </blockquote>
<p>
<div class="figure" id="figure_3.1"><p><a rel="lightbox" title="Figure 3.1"  href="images/broder_search_process.png"><img src="images/broder_search_process.png" width=400px></a><div class="caption"> <b>Figure 3.1:</b>  The standard model of the search process, adapted from <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>. 
</div><!-- end div caption --></div> <!-- end div figure --><p>
This model is elaborated by <a href="sui_references.html#sutcliffe1998" title="A.G.
  Sutcliffe and M.&nbsp;Ennis.
Towards a cognitive theory of information retrieval.
<i>Interacting with Computers</i>, 10:321&ndash;351, 1998.">Sutcliffe and Ennis, 1998</a>'s oft-cited information seeking process model, which they formulate as a cycle consisting of four main activities: <p>
<ul>
<li> Problem identification, <li> Articulation of information need(s), <li> Query formulation, and <li> Results evaluation. </ul>
<p>
<a href="sui_references.html#sutcliffe1998" title="A.G.
  Sutcliffe and M.&nbsp;Ennis.
Towards a cognitive theory of information retrieval.
<i>Interacting with Computers</i>, 10:321&ndash;351, 1998.">Sutcliffe and Ennis, 1998</a> associate different types of search strategies with each of these activities (for instance, scanning titles is associated with results evaluation). Their model also accounts for the role of the searcher's knowledge, the system, the information collections, and of searching in general. <p>
<div id="index_information needs_1"></div>
<div id="index_query specification_1"></div>
<p>
<p>
A similar four-phase framework is described by <a href="sui_references.html#shneiderman1997csu" title="B.&nbsp;Shneiderman, D.&nbsp;Byrd, and WB&nbsp;Croft.
Clarifying Search: A User-Interface Framework for Text Searches.
<i>DL Magazine</i>, January 1997.">Shneiderman et&nbsp;al.,   1997</a>, who outline the main steps as: <p>
<ul>
<li> Query Formulation, <li> Action (running the query), <li> Review of Results, <li> Refinement. </ul>
<p>
<a href="sui_references.html#marchionini2008" title="G.&nbsp;Marchionini and R.W. White.
Find What You Need, Understand What You Find.
<i>Journal of Human-Computer Interaction</i>, 23(3):205&ndash;237, 2008.">Marchionini and White,   2008</a>'s description of the information-seeking process consists of: <p>
<ul>
<li> Recognizing a need for information, <li> Accepting the challenge to take action to fulfill the need, <li> Formulating the problem, <li> Expressing the information need in a search system, <li> Examination of the results, <li> Reformulation of the problem and its expression, and <li> Use of the results. </ul>
<p>
These represent the core actions within general information seeking tasks. Figure <a href="#figure_3.1"><b>3.1</b></a> from (<a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>) illustrates the process, in tandem with a sketch of the information access system that is used within the process. Standard Web search engines support query specification, examination of retrieval results, and to some degree, query reformulation. The other steps are not supported well in today's Web search interfaces, but systems that support <i> sensemaking</i> (see below) do attempt to help with problem formulation, information re-organization, and creation of new representations from gathered information. These models are based primarily on observations of people engaged in information seeking processes. <p>
<div id="index_sensemaking_1"></div>
<p>
</div> <!-- end div section -->
<div class="section" id="section_3.2"><h2>3.2: Cognitive Models of Information Seeking</h2>
<p>
<p>
A cognitive account of the standard model can be derived from Norman's influential model of general task performance (<a href="sui_references.html#norman88" title="D.A. Norman.
<i>The Psychology of Everyday Things</i>.
Basic Books, New York, 1988.">Norman, 1988</a>), which presents a broad perspective on how people operate in the world. According to this model, a person must first have a basic idea of what they want -- the goal to be achieved. Then they use their mental model of the situation to decide on some kind of action in the world that affects themselves, other people, or objects, with the aim of achieving their goal. The notion of a <i> mental model</i> is often invoked in the field of HCI as a mechanism for explaining one's understanding of a system or interface. A person's mental model is a dynamic, internal representation of a problem situation or a system which can take inputs from the external world and return predictions of effects for those inputs (<a href="sui_references.html#marchionini1989iss" title="G.&nbsp;Marchionini.
Information-seeking strategies of novices using a full-text electronic
  encyclopedia.
<i>Journal of the American Society for Information Science</i>,
  40(1):54&ndash;66, 1989.">Marchionini,   1989</a>). <p>
<div id="index_mental models_1"></div>
<p>
<div class="figure" id="figure_3.2"><p><a rel="lightbox" title="Figure 3.2"  href="images/norman-cycle.png"><img src="images/norman-cycle.png" width=400px></a><div class="caption"> <b>Figure 3.2:</b>  A sketch of Norman's cognitive execution-evaluation model, adapted from <a href="sui_references.html#norman88" title="D.A. Norman.
<i>The Psychology of Everyday Things</i>.
Basic Books, New York, 1988.">Norman, 1988</a>. 
</div><!-- end div caption --></div> <!-- end div figure --><p>
Norman divides actions into the doing (<i> execution</i>) and the checking (<i> evaluation</i>) of the result. After taking an action, a person must assess what kind of change occurred, if any, and whether or not the action achieved the intended goal (see Figure <a href="#figure_3.2"><b>3.2</b></a>). Norman describes the gap between what was intended and what was achieved as the <i> gulf of execution</i>, and the challenge of determining whether or not one's goals have been met as the <i> gulf of evaluation</i>. In the case of user interface design, the smaller these gulfs, the more usable the system. This also suggests that the less knowledge a person has about their task, the less they will be able to successfully formulate goals and assess results. <p>
<p>
Norman's model can be seen as providing cognitive underpinnings for the standard model as described in the previous section. Recognizing a need for information is akin to formulating and becoming conscious of a goal. Formulating the problem and expressing the information need via queries or navigation in a search system corresponds to executing actions, and examination of the results to determine if the information need is satisfied corresponds to the evaluation part of the model. Query reformulation is needed if the gulf between the goal and the state of the world is too large. <p>
<p>
</div> <!-- end div section -->
<div class="section" id="section_3.3"><h2>3.3: The Dynamic (Berry-Picking) Model</h2>
<p>
<div id="index_berry-picking_1"></div>
<p>
The standard model of the information seeking process contains an underlying assumption that the user's information need is static and the information seeking process is one of successively refining a query until all and only those documents relevant to the original information need have been retrieved. However, observational studies of the information seeking process find that searchers' information needs change as they interact with the search system. Searchers learn about the topic as they scan retrieval results and term suggestions, and formulate new subquestions as previously posed subquestions are answered. Thus while useful for describing the basics of information access systems, the standard interaction model has been challenged on many fronts (<a href="sui_references.html#bates89" title="M.J. Bates.
The design of browsing and berrypicking techniques for the on-line search
  interface.
<i>Online Review</i>, 13(5):407&ndash;431, 1989.">Bates, 1989</a>, <a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press."> O'Day and Jeffries, 1993</a>, <a href="sui_references.html#borgman96" title="C.L. Borgman.
Why are online catalogs still hard to use?
<i>Journal of the American Society for Information Science</i>,
  47(7):493&ndash;503, 1996."> Borgman, 1996b</a>, <a href="sui_references.html#hendry97" title="D.G. Hendry and
  D.J. Harper.
An informal information-seeking environment.
<i>Journal of the American Society for Information Science</i>,
  48(11):1036&ndash;1048, 1997."> Hendry and Harper, 1997</a>, <a href="sui_references.html#cousins97b" title="S.B. Cousins.
<i>Reification and Affordances in a User Interface for Interacting with
  Heterogeneous Distributed Applications</i>.
PhD thesis, Stanford University, May 1997."> Cousins, 1997</a>). <p>
<div class="figure" id="figure_3.3"><p><a rel="lightbox" title="Figure 3.3"  href="images/berrypicking.png"><img src="images/berrypicking.png" width=400px></a><div class="caption"> <b>Figure 3.3:</b>  A sketch of an information seeker engaged in &#8220;berry-picking&#8221; style information seeking process, in which the query shifts as relevant information and documents are found along the way. 
</div><!-- end div caption --></div> <!-- end div figure --><p>
<a href="sui_references.html#bates89" title="M.J. Bates.
The design of browsing and berrypicking techniques for the on-line search
  interface.
<i>Online Review</i>, 13(5):407&ndash;431, 1989.">Bates, 1989</a> proposed the <i> berry-picking</i> model of information seeking, which has two main points. The first is that, in the process of reading and learning from the information encountered throughout the search process, the searchers' information needs, and consequently their queries, continually shift (see Figure <a href="#figure_3.3"><b>3.3</b></a>). Information encountered at one point in a search may lead in a new, unanticipated direction. The original goal may become partly fulfilled, thus lowering the priority of one goal in favor of another. The second point is that searchers' information needs are not satisfied by a single, final retrieved set of documents, but rather by a series of selections and bits of information found along the way. This is in contrast to the assumption that the main goal of the search process is to hone down the set of retrieved documents into a perfect match of the original information need. <p>
The berry-picking model is supported by a number of observational studies (<a href="sui_references.html#ellis89" title="D.&nbsp;Ellis.
A behavioural model for information retrieval system design.
<i>Journal of Information Science</i>, 15:237&ndash;247, 1989.">Ellis, 1989</a>, <a href="sui_references.html#borgman96" title="C.L. Borgman.
Why are online catalogs still hard to use?
<i>Journal of the American Society for Information Science</i>,
  47(7):493&ndash;503, 1996."> Borgman, 1996b</a>), including that of <a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press.">O'Day and Jeffries, 1993</a>, who interviewed 15 business analysts about their typical search tasks. They found that the information seeking process consisted of a series of interconnected but diverse searches. They also found that search results for a goal tended to trigger new goals, and hence search in new directions, but that the context of the problem and the previous searches was carried from one stage of search to the next. Finally, the main value of the search was found to reside in the accumulated learning and acquisition of information that occurred during the search process, rather than in the final results set. <p>
<p>
<div id="index_berry-picking_2"></div>
<p>
</div> <!-- end div section -->
<div class="section" id="section_3.4"><h2>3.4: Information Seeking in Stages</h2>
<p>
<p>
Some researchers have examined how the information seeking process develops over extended periods of time. <a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991.">Kuhlthau, 1991</a> conducted studies that showed that, for complex information seeking tasks, searchers go through different stages, both in terms of their knowledge of and their attitude towards the task. To develop her model of the information seeking process, <a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991.">Kuhlthau, 1991</a> conducted numerous field studies as well as focused case studies. The final field study was very large (compared to most such studies), involving 385 academic, public, and school library users at 21 sites. Participants were primarily students in high school or college whose task was to write a term paper or research paper. In these studies, the information seeking task took place over several months, and in most cases the students were assigned the topic rather than choosing it themselves. <a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991.">Kuhlthau, 1991</a>'s method was also unusual in that in addition to asking participants about their search process, she also asked questions about their emotional state. <p>
<p>
<a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991.">Kuhlthau, 1991</a>'s findings revealed both a common information access process and common emotional patterns. She divides the process of information seeking into six stages: <p>
<ul>
<p>
<li> <i> Initiation:</i> The task is to recognize a need for information. Searches relate to general background knowledge. As the participant becomes aware of their lack of understanding, feelings of uncertainty and apprehension are common. Thoughts center on comprehending the task and relating the problem to prior experience. <p>
<li> <i> Selection:</i> The task is to select the general topic or the approach to pursue. Thoughts are general and undifferentiated, and center on requirements, time constraints, and which topic or approach will yield the best outcome. Feelings of uncertainty often give way to optimism after the selection is made. <p>
<li> <i> Exploration:</i> The task is to investigate information on the general topic in order to extend understanding. At this stage, an inability to express what information is needed degrades the participant's ability to formulate queries and judge relevance of retrieval results. Information encountered at this stage often conflicts with pre-existing knowledge and information from different sources can seem contradictory and incompatible. This phase is characterized by feelings of confusion, uncertainty, and doubt, and participants may feel discouraged or inadequate, or may feel frustrated with the information access system itself. <p>
<li> <i> Formulation:</i> This phase marks the turning point in the process, in which a focused perspective on the topic emerges, resolving some of the conflicting information. Searches may be conducted to verify the working hypotheses. A change in feelings is experienced, with uncertainty reducing and confidence growing. Unfortunately, half of the study participants did not show evidence of successfully reaching a focused perspective at any time during their search process. <p>
<li> <i> Collection:</i> At this stage the search system is most productively useful for the participant, since the task is to gather information related to a focused topic. Searches are used to find information to define, extend, and support the focus. Relevance judgements become more accurate and feelings of confidence continue to increase. <p>
<li> <i> Presentation:</i> In this phase, the final searches are done; searches should be returning information that is either redundant with what has been seen before or of diminishing relevance. The participants commonly experience feelings of relief, and satisfaction if the search went well, or disappointment if not. <p>
</ul>
<p>
<p>
<p>
Similar results were found by <a href="sui_references.html#vakkari2000rac" title="P.&nbsp;Vakkari.
Relevance And Contributing Information Types Of Searched Documents In Task
  Performance.
<i>Proceedings of the 23th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'00)</i>, pages
  2&ndash;9, 2000.">Vakkari, 2000b</a>, who studied 11 students doing research for a masters project over 4 months. <a href="sui_references.html#vakkari2000rac" title="P.&nbsp;Vakkari.
Relevance And Contributing Information Types Of Searched Documents In Task
  Performance.
<i>Proceedings of the 23th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'00)</i>, pages
  2&ndash;9, 2000.">Vakkari, 2000b</a> writes: <p>
<blockquote>
&#8220;In general, all the participants proceeded in their task according to <a href="sui_references.html#kuhlthau1991isp" title="C.C. Kuhlthau.
Inside the search process: Information seeking from the user's perspective.
<i>Journal of the American Society for Information Science</i>,
  42(5):361&ndash;371, 1991.">Kuhlthau, 1991</a>'s model at varying paces. In the first search session, the students were moving from topic selection to exploration of the topic. In the middle of their task they were typically exploring the topic and trying to formulate a research problem. By the end of the project most of the students had been able to construct a focus and they were at the collection or presentation stage.&#8221; </blockquote>
<p>
Note that these stages characterize changes in searches over time for a deep and complex information need, and are not necessarily representative for more light-weight tasks. Note also that these studies reflect the experiences of students doing required, challenging tasks; it is likely that the feelings of apprehension reported might not be observed in other information-intensive task environments. Additionally, the tools used by Kuhlthau's students were probably less familiar and usable than search tools available today. <p>
<p>
</div> <!-- end div section -->
<div class="section" id="section_3.5"><h2>3.5: Information Seeking as a Strategic Process</h2>
<p>
<p>
Some information seeking models cast the process in terms of <i> strategies</i> and how choices for next steps are made. As <a href="sui_references.html#marchionini2000ahc" title="G.&nbsp;Marchionini, G.&nbsp;Geisler, and B.&nbsp;Brunk.
Agileviews: A Human-Centered Framework For Interfaces To Information Spaces.
<i>Proceedings of the American Society for Information Science Annual
  Meeting</i>, 37:271&ndash;80, 2000.">Marchionini et&nbsp;al.,   2000</a> note, &#8220;search is an interplay of analytical and interactive problem solving strategies.&#8221; In some cases, the strategy-oriented models are meant to reflect conscious planning behavior by expert searchers. In others, the models are meant to capture the less planned, potentially more reactive behavior of a typical information seeker. The next subsections discuss the theoretical characterizations of information seeking strategies. <p>
<div class="subsection" id="subsection_3.5.1"><h3>3.5.1: Strategies as Sequences of Tactics</h3>
<p>
<p>
<a href="sui_references.html#bates1979ist" title="M.J. Bates.
Information search tactics.
<i>Journal of the American Society for Information Science</i>,
  30(4):205&ndash;214, 1979.">Bates, 1979</a> suggests that a searcher's behavior can be characterized by search strategies which in turn are made up of sequences of search <i> tactics</i>. Tactics are the immediate choices or actions taken in the light of the current focus of attention and state of the search. Strategies refer to combinations of tactics used in order to accomplish information access tasks. Thus strategies are sequences of tactics which, viewed together, help achieve some aspect or subgoal of the user's main goals. Bates enumerates a set of search tactics which she groups into four categories, which are paraphrased slightly below. <p>
<div id="index_query term suggestions_2"></div>
<div id="index_reformulation_1"></div>
<div id="index_Boolean syntax_3"></div>
<div id="index_hyperlinks_2"></div>
<div id="index_monitoring_1"></div>
<p>
<ul>
<li> <i> Term tactics:</i> refer to tactics for adjusting words and phrases within the current query. These include making use of term suggestions provided by the search system and selecting terms from an online thesaurus. <p>
<li> <i> Information structure tactics:</i> are techniques for moving through information or link structures to find sources or information within sources. An example of an information structure tactic for an academic researcher is looking at the research articles that cite a given paper, and following the citation chain. Another example is, when searching within an online collection or Web site, following promising hyperlinks or searching within a category of information, e.g., searching only within the technology section of a news Web site. <p>
<li> <i> Query reformulation tactics:</i> examples include narrowing a given query specification by using more specific terms or gaining more control over the structure of the query by using Boolean operators. <p>
<li> <i> Monitoring tactics:</i> monitoring refers to keeping track of a situation as it unfolds. Bates discusses several high-level monitoring tactics, including making a cost-benefit analysis of current or anticipated actions (weighing), continuously comparing the current state with the original goal (checking; note the similarity to <a href="sui_references.html#norman88" title="D.A. Norman.
<i>The Psychology of Everyday Things</i>.
Basic Books, New York, 1988.">Norman, 1988</a>'s gulf of evaluation), recognizing patterns across common strategies, and recording incomplete paths to enable returning at a later time. Bates also notes that one of the fundamental issues in search strategies is determining when to stop; monitoring tactics can help with this determination. </ul>
<p>
A question arises as to how a searcher who is monitoring their search knows to stop following one strategy and take up another. <a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press.">O'Day and Jeffries, 1993</a> defined a number of <i> triggers</i> that motivate a seeker to switch from one search strategy to another. These triggers include: <p>
<ul>
<li> The completion of one step and beginning of the next logical step in a plan, <li> Encountering something interesting that provides a new way of thinking about a topic of interest, or a new, interesting angle to explain a topic or problem, <li> Encountering a change or violation of previous expectations that requires further investigation, and <li> Encountering inconsistencies with or gaps in previous understanding that requires further investigation. </ul>
<p>
<p>
O'Day and Jeffries also attempted to identify stop conditions -- circumstances under which people decided to stop searching. These were fuzzier than the triggers for changing strategies, but they did find that people stopped searching when: <ul>
<li> There were no more compelling triggers, <li> An &#8220;appropriate&#8221; amount of material had been found, or <li> There was a specific inhibiting factor (such as discovering a market was too small to be worth researching). </ul>
<p>
These stop conditions can be cast in terms of a cost-benefit analysis (see discussion below); for example, the second point might be interpreted as a drop below a threshold for continuing the current line of inquiry. <p>
<a href="sui_references.html#bates1979ist" title="M.J. Bates.
Information search tactics.
<i>Journal of the American Society for Information Science</i>,
  30(4):205&ndash;214, 1979.">Bates, 1979</a> notes that some search tasks are straightforward enough that a strategy per se is not required. Simple fact-searching on the Web is an example of this; the searcher opens a Web browser, navigates to a search engine entry form, types in their information need, and scans the retrieval results to find the answer or a link to a page that contains the answer. <p>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.5.2"><h3>3.5.2: Cost Structure Analyses and Information Foraging Theory</h3>
<p>
<div id="index_foraging theory_1"></div>
<p>
<p>
As mentioned above, <a href="sui_references.html#bates1979ist" title="M.J. Bates.
Information search tactics.
<i>Journal of the American Society for Information Science</i>,
  30(4):205&ndash;214, 1979.">Bates, 1979</a> discusses the importance of monitoring the progress of the current search and weighing the costs and benefits of continuing with the current strategy or trying something else. <a href="sui_references.html#russell93" title="D.M. Russell, M.J.
  Stefik, P.&nbsp;Pirolli, and S.K. Card.
The cost structure of sensemaking.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Conceptual Analysis of Users and Activity, pages
  269&ndash;276, 1993.">Russell et&nbsp;al., 1993</a> also cast the activity of monitoring the progress of a search strategy relative to a goal or subgoal in terms of a <i> cost structure analysis</i>, or an analysis of diminishing returns. This account assumes that at any point in the search process, the user is pursuing the strategy that has the highest expected utility. If, as a consequence of some local tactical choices, another strategy presents itself as being of higher utility than the current one, the current one is (temporarily or permanently) abandoned in favor of the new strategy. <p>
This cost structure analysis method was subsequently expanded into <i> information foraging theory</i> by <a href="sui_references.html#pirolli1999if" title="P.&nbsp;Pirolli and
  S.K. Card.
Information foraging.
<i>Psychological Review</i>, 106(4):643&ndash;675, 1999.">Pirolli and Card, 1999</a>. This theoretical framework contains several ideas relevant to understanding the search process. It takes an evolutionary stance, noting that humans' ancestors evolved perceptual and cognitive structures that were well-adapted for exploring the environment in the task of finding food. The theory assumes that, in the modern world, awash with information of our own creation, humans transfer food-finding cognitive mechanisms over to the task of exploring, finding, and ultimately &#8220;consuming&#8221; information (<a href="sui_references.html#pirolli2007" title="Peter Pirolli.
<i>Information Foraging Theory</i>.
Oxford University Press, 2007.">Pirolli, 2007</a>). <p>
Information foraging theory attempts to model and make predictions about peoples' strategies for navigating within information structures. One important concept is a cost-benefit analysis for navigation, in which searchers make tradeoffs between two questions. <a href="sui_references.html#nielsen2003ifw" title="J.&nbsp;Nielsen.
Information Foraging: Why Google Makes People Leave Your Site Faster, 2003.
http://www.useit.com/alertbox/20030630.html.">Nielsen, 2003a</a> formulates this as: <p>
<ul>
<li> (i) What gain can I expect from a specific information nugget (such as a Web page)? <li> (ii) What is the likely cost in terms of time and effort of discovering and consuming that information? </ul>
<p>
Thus, an information consumer compares the cost of evaluation and immediate &#8220;consumption&#8221; of information with the cost of additional search. This model can account for the decreasing returns on, say, reading information from a search results list: after some number of documents on a topic have been read, the tradeoff between finding new information versus reading information already seen or of lower quality begins to tip in favor of ending the information consumption session. That is, the theory assumes that search strategies evolve toward those that maximize the ratio of valuable information gained to unit of cost for searching and reading. <p>
<p>
When foraging, information can appear in &#8220;patches&#8221;; it might make sense to read a few pieces of information from one Web site, and then move to another Web site to get more variety in the &#8220;diet&#8221;; however, one must consider the payoff in finding new kinds of information versus the cost of getting to a new good patch of information. <a href="sui_references.html#nielsen2003ifw" title="J.&nbsp;Nielsen.
Information Foraging: Why Google Makes People Leave Your Site Faster, 2003.
http://www.useit.com/alertbox/20030630.html.">Nielsen, 2003a</a> points out that in the early days of the Web, search quality was poor and there was not very much content available, so it made more sense to focus all one's attention on an information-rich Web site once it was found. But as the content increased and search results improved in the late 1990s, the cost of finding high-quality additional sources of information fell, and so it often became more cost-effective and advantageous to forage briefly on each of a variety of different sites. <p>
<p>
<div id="index_foraging theory_2"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.5.3"><h3>3.5.3: Browsing vs. Search as an Information Seeking Strategy</h3>
<p>
<div id="index_navigation_3"></div>
<p>
A bedrock psychological result from cognitive science is <i> recognition over recall</i>; that is, it is usually easier for a person to recognize something by looking for it than it is to think up how to describe that thing. A familiar example is experienced by learners of a foreign language; it is usually easier to read a sentence in that language than to generate a sentence oneself. This principle applies to information seeking as well. Rather than requiring the searcher to issue keyword queries and scan retrieval results, the system can provide the searcher with structure that characterizes the available information. <p>
<div id="index_recognition over recall_2"></div>
<p>
There are a number of theories and frameworks that contrast <i> querying/searching</i> and <i> browsing/navigating,</i> along several dimensions (<a href="sui_references.html#belkin93" title="N.&nbsp;Belkin, P.&nbsp;G.
  Marchetti, and C.&nbsp;Cool.
Braque &ndash; design of an interface to support user interaction in information
  retrieval.
<i>Information Processing and Management</i>, 29(3):325&ndash;344, 1993.">Belkin et&nbsp;al., 1993</a>, <a href="sui_references.html#chang93" title="Shan-Ju Chang and
  Ronald&nbsp;E. Rice.
Browsing: A multidimensional framework.
<i>Annual Review of Information Science and Technology</i>, 28:231&ndash;276,
  1993."> Chang and Rice, 1993</a>, <a href="sui_references.html#marchionini95" title="Gary Marchionini.
<i>Information Seeking in Electronic Environments</i>.
Cambridge University Press, 1995."> Marchionini, 1995</a>, <a href="sui_references.html#waterworth91" title="J.A.
  Waterworth and M.H. Chignell.
A model of information exploration.
<i>Hypermedia</i>, 3(1):35&ndash;58, 1991."> Waterworth and Chignell, 1991</a>). One way to distinguish searching versus browsing is to note that search queries tend to produce new, ad hoc collections of information that have not been gathered together before, whereas navigation/browsing refers to selecting links or categories that produce pre-defined groups of information items. Browsing also involves following a chain of links, switching from one view to another, in a sequence of scan and select operations. Browsing can also refer to the casual, mainly undirected exploration of navigation structures. <a href="sui_references.html#hertzum96" title="Morten Hertzum
  and Erik Frokjaer.
Browsing and querying in online documentation: A study of user interfaces and
  the interaction process.
<i>ACM Transactions on Computer-Human Interaction (ToCHI)</i>,
  3(2):136&ndash;161, 1996.">Hertzum and Frokjaer, 1996</a> word the contrast as follows: <p>
<div id="index_navigation structure_2"></div>
<div id="index_hyperlinks_3"></div>
<div id="index_categories_2"></div>
<p>
<blockquote>
&#8220;Browsing is a retrieval process where the users navigate through the text database by following links from one piece of text to the next, aiming to utilize two human capabilities ... the greater ability to recognize what is wanted over being able to describe it and ... the ability to skim or perceive at a glance. This allows users to evaluate rapidly rather large amounts of text and determine what is useful.&#8221; </blockquote>
<p>
<a href="sui_references.html#aula-dissertation" title="A.&nbsp;Aula.
<i>Studying user strategies and characteristics for developing web search
  interfaces</i>.
PhD thesis, University of Tampere, Finland, Ph.D. Dissertation, Dissertations
  in Interactive Technology, Number 3., 2005.">Aula, 2005</a> writes: <p>
<blockquote>
&#8220;Considered in cognitive terms, searching is a more analytical and demanding method for locating information than browsing, as it involves several phases, such as planning and executing queries, evaluating the results, and refining the queries, whereas browsing only requires the user to recognize promising-looking links.&#8221; </blockquote>
<p>
Thus, in principle, in many situations it is less mental work to scan a list of hyperlinks and choose the one that is of interest than it is to think up the appropriate query terms to describe the information need. But there are diminishing returns to scanning links if it takes too long to find the label of interest, and there is always the possibility that the desired information is not visible. That is, browsing works only so long as appropriate links are available, and they have meaningful cues about the underlying information. <p>
In a comparative study with 96 student participants finding information in online software manuals, <a href="sui_references.html#hertzum96" title="Morten Hertzum
  and Erik Frokjaer.
Browsing and querying in online documentation: A study of user interfaces and
  the interaction process.
<i>ACM Transactions on Computer-Human Interaction (ToCHI)</i>,
  3(2):136&ndash;161, 1996.">Hertzum and Frokjaer, 1996</a> found that browsing a hierarchical table of contents produced the best mean performance (compared to Boolean queries) but did not provide <i> stable</i> good performance, presumably because for some tasks the information structure used for the browsing was not suitable for the information need. They concluded that browsing is well-suited for some tasks, but unsuited for others. A study of the SuperBook system (<a href="sui_references.html#landauer93" title="T.K. Landauer,
  D.E. Egan, J.R. Remde, M.E. Lesk, C.C. Lochbaum, and D.&nbsp;Ketchum.
Enhancing the usability of text through computer delivery and formative
  evaluation: the superbook project.
In C.&nbsp;McKnight, A.&nbsp;Dillon, and J.&nbsp;Richardson, editors, <i>Hypertext: A
  Psychological Perspective</i>, pages 71&ndash;136. Ellis Horwood, 1993.">Landauer et&nbsp;al., 1993</a>) found similar results: when the queries were well-represented by hits on a table-of-contents representation, browsing worked better than keyword search, but did not improve results when the information structure did not match the information need. <p>
The field of information architecture makes a distinction between <i> information structure</i> and <i> navigation structure</i>. Information structure defines the organization, textual labels, and controlled vocabulary terms for the content items of the site (<a href="sui_references.html#morville2006iaw" title="P.&nbsp;Morville and L.&nbsp;Rosenfeld.
<i>Information Architecture for the World Wide Web</i>.
O'Reilly, 2006.">Morville and Rosenfeld,   2006</a>). Navigation structure determines the paths that can be taken through the information structure, via the hyperlinked user interface (<a href="sui_references.html#newman2000ssa" title="M.W. Newman
  and J.A. Landay.
Sitemaps, storyboards, and specifications: a sketch of Web site design
  practice.
In <i>Proceedings of the 3rd conference on Designing interactive systems:
  processes, practices, methods, and techniques</i>, pages 263&ndash;274. ACM New
  York, NY, USA, 2000.">Newman and Landay, 2000</a>). Thus the success of a browsing interface depends in part on how well the presented information matches searchers' information needs and expectations. Another important property of browsing interfaces is that they should seamlessly integrate keyword querying with navigation of the underlying information structure. Many Web sites use dynamically generated metadata to provide a flexible, browsable information structure. Chapter <a href="sui_ch8_navigation_and_search.html"><b>8</b></a> discusses information and navigation structures that aid in navigation and discovery within information collections. <p>
<div id="index_information architecture_1"></div>
<div id="index_information structure_1"></div>
<div id="index_navigation structure_3"></div>
<p>
<div id="index_navigation_4"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.5.4"><h3>3.5.4: Information Scent for Navigating Information Structures</h3>
<p>
<div id="index_information scent_1"></div>
<p>
When navigating within information structures, in order to make decisions about which information &#8220;patches&#8221; are promising to pursue, searchers must examine clues about where to find useful information. One part of <a href="sui_references.html#pirolli05" title="P.&nbsp;Pirolli and
  S.K. Card.
The sensemaking process and leverage points for analyst technology as
  identified through cognitive task analysis.
In <i>Proceedings of the 2005 International Conference on Intelligence
  Analysis</i>, McClean, VA, May 2005.">Pirolli and Card, 2005</a>'s information foraging theory discusses the notion of information <i> scent</i>: cues that provide searchers with concise information about content that is not immediately perceptible. <a href="sui_references.html#pirolli2007" title="Peter Pirolli.
<i>Information Foraging Theory</i>.
Oxford University Press, 2007.">Pirolli, 2007</a> notes that small pertubations in the accuracy of information scent can cause qualitative shifts in the cost of browsing; improvements in information scent are related to more efficient foraging. The detection of diminishing information scent is involved in decisions to leave an information patch. <p>
<div class="figure" id="figure_3.4"><p><a rel="lightbox" title="Figure 3.4(a)"  href="images/bls_homepage_original.png"><img src="images/bls_homepage_original.png" width=400px></a><p>(a)<br /><p><a rel="lightbox" title="Figure 3.4(b)"  href="images/bls_homepage.png"><img src="images/bls_homepage.png" width=400px></a><p>(b)<br /><div class="caption"> <b>Figure 3.4:</b>  (a) [Before] An early version of the home page for the U.S. Bureau of Labor Statistics, which hid most of the content behind graphics, requiring users to make guesses as to what kind of information is available, and where on the site it might reside, from <a href="sui_references.html#marchionini2003dgi" title="G.&nbsp;Marchionini and M.&nbsp;Levi.
Digital government information services: the Bureau of Labor statistics case.
<i>interactions</i>, 10(4):18&ndash;27, 2003.">Marchionini and Levi,   2003</a>. (b) [After] The same home page redesigned to have high-quality information scent; intended for heavy users of government statistics.  
</div><!-- end div caption --></div> <!-- end div figure --><p>
<a href="sui_references.html#furnas1997evn" title="G.W. Furnas.
Effective view navigation.
<i>Proceedings of the SIGCHI Conference on Human Factors in Computing
  Systems (CHI'97)</i>, pages 367&ndash;374, 1997.">Furnas, 1997</a> also discusses the idea of information scent, stating that a target has scent at a link if the associated outlink information would lead an information navigator to take that link in pursuit of the given target. Furnas puts forward the <i> navigability proposition</i> that states that in order for a target to be findable by navigation from anywhere in the information structure, the path to that target must have good scent at every link. <p>
<div id="index_navigability proposition_1"></div>
<p>
Search results listings must provide the user with clues about which results to click; the notion of information scent can be applied to this problem. <a href="sui_references.html#spool07" title="Jared Spool.
Scent of a web page: Getting users to what they want.
<i>Proceedings of the SIGCHI Conference on Human Factors in Computing
  Systems (CHI'07) Course Notes</i>, 2007.">Spool, 2007</a> suggests operationalizing the idea of information scent in Web site design by showing users informative hints about what kind of information will be found one hop away from the current Web page. One example suggestion is to augment links to product categories with a short list of the types of items to be found in that category. <a href="sui_references.html#nielsen2003ifw" title="J.&nbsp;Nielsen.
Information Foraging: Why Google Makes People Leave Your Site Faster, 2003.
http://www.useit.com/alertbox/20030630.html.">Nielsen, 2003a</a> suggests, for the design of Web site home pages, showcasing sample content and prominently displaying navigation and search features, so searchers have the &#8220;scent&#8221; for what can be found by exploring further on the web site. <a href="sui_references.html#nielsen2004b" title="J.&nbsp;Nielsen.
Deceivingly Strong Information Scent Costs Sales, 2004.
http://www.useit.com/alertbox/20040801.html.">Nielsen, 2004a</a> also points out that misleadingly strong scent can cause information browsers to overlook the best location to find their object of interest. Figure <a href="#figure_3.4"><b>3.4</b></a>b shows the home page of the U.S. government's Bureau of Labor Statistics Web site, which has been carefully designed to have good information scent. Its design was refined via several iterations of evaluation and redesign, progressively adding more information as the information needs of the users of the site became clear (<a href="sui_references.html#marchionini2003dgi" title="G.&nbsp;Marchionini and M.&nbsp;Levi.
Digital government information services: the Bureau of Labor statistics case.
<i>interactions</i>, 10(4):18&ndash;27, 2003.">Marchionini and Levi,   2003</a>). An early version of the interface is shown in Figure <a href="#figure_3.4"><b>3.4</b></a>a. In the earlier design, a graphical display of the main categories provided few cues about the rich information sources that lay behind them. <p>
<div id="index_hyperlinks_4"></div>
<div id="index_categories_3"></div>
<div id="index_information scent_2"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.5.5"><h3>3.5.5: Orienteering and other Incremental Strategies</h3>
<p>
<div id="index_orienteering_1"></div>
<p>
A commonly-observed search strategy is one in which the information seeker issues a quick, imprecise query in the hopes of getting into approximately the right part of the information space, and then doing a series of local navigation operations to get closer to the information of interest (<a href="sui_references.html#marchionini95" title="Gary Marchionini.
<i>Information Seeking in Electronic Environments</i>.
Cambridge University Press, 1995.">Marchionini, 1995</a>, <a href="sui_references.html#bates90b" title="M.J. Bates.
Where should the person stop and the information search interfaces start?
<i>Information Processing and Management</i>, 26(5), 1990."> Bates, 1990</a>). <a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press.">O'Day and Jeffries, 1993</a> use the term <i> orienteering</i> to describe search strategies in which searchers use information from their current situation to help determine where to go next, as opposed to trying to find the answer in one jump by writing a long complex query indicating the full information need. <p>
<p>
A number of studies have shown that searchers tend to start out with short or general queries, inspect the results, and then modify those queries in an incremental feedback cycle (<a href="sui_references.html#bates89" title="M.J. Bates.
The design of browsing and berrypicking techniques for the on-line search
  interface.
<i>Online Review</i>, 13(5):407&ndash;431, 1989.">Bates, 1989</a>, <a href="sui_references.html#waterworth91" title="J.A.
  Waterworth and M.H. Chignell.
A model of information exploration.
<i>Hypermedia</i>, 3(1):35&ndash;58, 1991."> Waterworth and Chignell, 1991</a>, <a href="sui_references.html#anick94" title="P.&nbsp;Anick.
Adapting a full-text information retrieval system to the computer
  troubleshooting domain.
In <i>Proceedings of the 17th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'94)</i>, pages
  349&ndash;358, 1994."> Anick, 1994</a>, <a href="sui_references.html#teevan2004pse" title="J.&nbsp;Teevan,
  C.&nbsp;Alvarado, M.S. Ackerman, and D.R. Karger.
The perfect search engine is not enough: a study of orienteering behavior in
  directed search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  415&ndash;422, 2004."> Teevan et&nbsp;al., 2004</a>, <a href="sui_references.html#eysenbach2002csa" title="G.&nbsp;Eysenbach and C.&nbsp;Kohler.
How do consumers search for and appraise health information on the world wide
  web? Qualitative study using focus groups, usability tests, and in-depth
  interviews.
<i>British Medical Journal</i>, 324(7337):573&ndash;577, 2002."> Eysenbach and Kohler,   2002</a>). <a href="sui_references.html#bates1979ist" title="M.J. Bates.
Information search tactics.
<i>Journal of the American Society for Information Science</i>,
  30(4):205&ndash;214, 1979.">Bates, 1979</a> also notes that a good tactic is to &#8220;break complex search queries down into subproblems and work on one problem at a time. This tactic is a well-established and productive technique in general problem solving.&#8221; <p>
<a href="sui_references.html#hertzum96" title="Morten Hertzum
  and Erik Frokjaer.
Browsing and querying in online documentation: A study of user interfaces and
  the interaction process.
<i>ACM Transactions on Computer-Human Interaction (ToCHI)</i>,
  3(2):136&ndash;161, 1996.">Hertzum and Frokjaer, 1996</a> noted this kind of behavior in a search interface usability study, finding that participants issue a sequence of queries rather than one all-inclusive query, enabling them to exploit information obtained earlier in the query sequence. This strategy is not without its drawbacks, as people can become too fixed on the their starting strategy. <a href="sui_references.html#hertzum96" title="Morten Hertzum
  and Erik Frokjaer.
Browsing and querying in online documentation: A study of user interfaces and
  the interaction process.
<i>ACM Transactions on Computer-Human Interaction (ToCHI)</i>,
  3(2):136&ndash;161, 1996.">Hertzum and Frokjaer, 1996</a> write: <p>
<div id="index_anchoring_1"></div>
<div id="index_thrashing_1"></div>
<p>
<blockquote>
&#8220;When a subject starts on a task, the first query expresses his initial, incomplete attempt to reach a solution. If this query does not provide the subject with the information needed, another must be formulated. At this point the user is subject to what psychologists call anchoring, i.e., the tendency to make insufficient adjustments to initial values when judging under uncertainty ... Thus, the subjects may tend to refrain from abandoning the initial query terms or from adjusting them very far, making the subsequent queries biased toward the initial one.&#8221; </blockquote>
<p>
<a href="sui_references.html#dmrussell06" title="D.M. Russell.
How do Google searchers behave? Improving search by divining intent, March
  2006.
Lecture available at
  http://hci.stanford.edu/cs547/abstracts/05-06/060310-russell.html.">Russell, 2006</a> also observed this kind of &#8220;thrashing&#8221; behavior in Google search engine logs. <p>
<a href="sui_references.html#teevan2004pse" title="J.&nbsp;Teevan,
  C.&nbsp;Alvarado, M.S. Ackerman, and D.R. Karger.
The perfect search engine is not enough: a study of orienteering behavior in
  directed search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  415&ndash;422, 2004.">Teevan et&nbsp;al., 2004</a> studied the information seeking behavior of 15 computer science graduate students over a period of one week. They observed extensive use of orienteering behavior, even when a more direct search might be more efficient. In most of these cases, participants began with an information resource that they were already familiar with, and followed links from that resource. For example, one student wanted to find the office number for a particular professor. As he had seen that professor's Web page previously, rather than search for it via a query on a search engine, he first navigated to the mathematics department Web page for the university, and from there to a link for faculty Web pages, and from there to the desired page. It might have required fewer steps to simply type in a query containing the professor's name and the phrase &#8220;office number&#8221; to find the same result, but this approach requires the searcher to spell the professor's name correctly, rely on the word &#8220;office&#8221; appearing on her Web page, and make other guesses about the behavior of the search engine that may not hold true. In other examples, searchers took conceptually large steps followed by smaller ones. Teevan et al. use the term <i> teleporting</i> to distinguish orienteering from a more directed behavior in which a long, precise query is typed. In a large study with 714 participants, <a href="sui_references.html#bergman2008ise" title="O.&nbsp;Bergman,
  R.&nbsp;Beyth-Marom, R.&nbsp;Nachmias, N.&nbsp;Gradovitch, and S.&nbsp;Whittaker.
Improved search engines and navigation preference in personal information
  management.
<i>ACM Transactions on Information Systems (TOIS)</i>, 26(4):1&ndash;24,
  2008.">Bergman et&nbsp;al., 2008</a> found that, when looking for files on their desktop computer, desktop search was used only 10-15&#37; of the time, with navigation of file structure strongly preferred. <p>
<div id="index_hyperlinks_5"></div>
<div id="index_teleporting_1"></div>
<p>
Thus, in many cases, searchers followed known paths that require small steps that move them closer to their goal, potentially reducing the likelihood of error. <a href="sui_references.html#teevan2004pse" title="J.&nbsp;Teevan,
  C.&nbsp;Alvarado, M.S. Ackerman, and D.R. Karger.
The perfect search engine is not enough: a study of orienteering behavior in
  directed search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  415&ndash;422, 2004.">Teevan et&nbsp;al., 2004</a> speculated that this approach is cognitively less taxing than fully specifying a query, as searchers do not have to articulate exactly what they are looking for precisely. <a href="sui_references.html#teevan2004pse" title="J.&nbsp;Teevan,
  C.&nbsp;Alvarado, M.S. Ackerman, and D.R. Karger.
The perfect search engine is not enough: a study of orienteering behavior in
  directed search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  415&ndash;422, 2004.">Teevan et&nbsp;al., 2004</a> also noted that this kind of behavior allows the searcher to retain information about the context in which the information occurs. <p>
The typical use of a Web search engine is often incremental in the fashion described above. This may be in part because today Web search engines are very fast; a typical query returns results within a fraction of a second. This makes natural a strategy that relies on &#8220;testing the water&#8221; with general queries followed by rapidly narrowing the results with reformulation. It is well-known from search engine query logs that a large proportion of search sessions contain query reformulations (<a href="sui_references.html#jansen2005tca" title="B.J. Jansen,
  A.&nbsp;Spink, and J.O. Pedersen.
A Temporal Comparison Of Altavista Web Searching.
<i>Journal Of The American Society For Information Science And
  Technology</i>, 56(6):559&ndash;570, 2005.">Jansen et&nbsp;al., 2005</a>, <a href="sui_references.html#jansen2007dsw" title="B.J. Jansen,
  A.&nbsp;Spink, C.&nbsp;Blakely, and S.&nbsp;Koshman.
Defining a Session on Web Search Engines.
<i>Journal Of The American Society For Information Science And
  Technology</i>, 58(6):862&ndash;871, 2007."> Jansen et&nbsp;al., 2007a</a>). It is furthermore known that searchers tend to look at only the top-ranked retrieved results (<a href="sui_references.html#joachims2005aic" title="T.&nbsp;Joachims,
  L.&nbsp;Granka, B.&nbsp;Pan, H.&nbsp;Hembrooke, and G.&nbsp;Gay.
Accurately Interpreting Clickthrough Data As Implicit Feedback.
<i>Proceedings of the 28th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'05)</i>, pages
  154&ndash;161, 2005.">Joachims et&nbsp;al., 2005</a>, <a href="sui_references.html#granka2004eta" title="L.A. Granka,
  T.&nbsp;Joachims, and G.&nbsp;Gay.
Eye-tracking analysis of user behavior in WWW search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  478&ndash;479, 2004."> Granka et&nbsp;al., 2004</a>). This suggests that the orienteering strategy is a common one for web search: users issue general queries, get information about the results, reformulate based on information seen in the results, and then navigate to promising-looking links or else give up. <p>
Some of today's Web search engines support longer queries well, and there is evidence that expert searchers tend to issue longer queries. If this trend continues, and/or if Web search engines begin to support full natural language queries reliably, searchers may begin to use more teleporting in their queries. <p>
<div id="index_long queries_1"></div>
<p>
<div id="index_orienteering_2"></div>
<p>
</div> <!-- end div subsection -->
</div> <!-- end div section -->
<div class="section" id="section_3.6"><h2>3.6: Sensemaking: Search as Part of a Larger Process</h2>
<p>
<div id="index_sensemaking_2"></div>
<p>
It is convenient to divide the entire information access process into two main components: information retrieval through searching and browsing, and analysis and synthesis of results. This broader process is often referred to in the literature as <i> sensemaking</i> (<a href="sui_references.html#russell93" title="D.M. Russell, M.J.
  Stefik, P.&nbsp;Pirolli, and S.K. Card.
The cost structure of sensemaking.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Conceptual Analysis of Users and Activity, pages
  269&ndash;276, 1993.">Russell et&nbsp;al., 1993</a>, <a href="sui_references.html#russell:bll" title="D.M. Russell,
  M.&nbsp;Slaney, Y.&nbsp;Qu, and M.&nbsp;Houston.
Being literate with large document collections: Observational studies and cost
  structure tradeoffs.
In <i>Proceedings of the 39th Annual Hawaii International Conference on
  System Sciences (HICSS'06)</i>, 2006."> Russell et&nbsp;al., 2006</a>, <a href="sui_references.html#pirolli05" title="P.&nbsp;Pirolli and
  S.K. Card.
The sensemaking process and leverage points for analyst technology as
  identified through cognitive task analysis.
In <i>Proceedings of the 2005 International Conference on Intelligence
  Analysis</i>, McClean, VA, May 2005."> Pirolli and Card, 2005</a>). Sensemaking refers to an iterative process of formulating a conceptual representation from of a large volume of information. Search plays only one part in this process; some sensemaking activities involve search throughout, while others consist of doing a batch of search followed by a batch of analysis and synthesis. Sensemaking is most often applied to information-intensive tasks such as intelligence analysis, scientific research, and the legal discovery process. <p>
<div id="index_intelligence analysts_1"></div>
<p>
Several studies have elucidated the different components of sensemaking. A study by <a href="sui_references.html#cowley2005gbi" title="P.&nbsp;Cowley,
  L.&nbsp;Nowell, and J.&nbsp;Scholtz.
Glass Box: An Instrumented Infrastructure for Supporting Human Interaction
  with Information.
<i>Proceedings of the 38th Annual Hawaii International Conference on System
  Sciences (HICSS'05)</i>, pages 296c&ndash;296c, 2005.">Cowley et&nbsp;al., 2005</a> of nine intelligence analysts working in a simulated task environment found that they spent on average an equal amount of time in a Web browser (searching and reading results listings and documents themselves), in a word processor (saving references and analyzing them), and in the file system (organizing files and directories and using the desktop) (<a href="sui_references.html#wright2006sac" title="W.&nbsp;Wright,
  D.&nbsp;Schroh, P.&nbsp;Proulx, A.&nbsp;Skaburskis, and B.&nbsp;Cort.
The Sandbox for Analysis&ndash;Concepts and Methods.
In <i>Proceedings of the SIGCHI Conference on Human Factors in Computing
  Systems (CHI'06)</i>. ACM, 2006.">Wright et&nbsp;al., 2006</a>). <p>
<a href="sui_references.html#patterson2001pvc" title="ES&nbsp;Patterson, EM&nbsp;Roth, and DD&nbsp;Woods.
Predicting Vulnerabilities in Computer-Supported Inferential Analysis under
  Data Overload.
<i>Cognition, Technology &amp; Work</i>, 3(4):224&ndash;237, 2001.">Patterson et&nbsp;al.,   2001</a>, in a study of intelligence analysts, noted that a tool is needed that &#8220;would allow the easy manipulation, viewing, and tagging of small text bundles, as well as aids for identifying, tracking, and revising judgments about relationships between data.&#8221; Their study also suggested that analysts need tools to help to corroborate data and rule out competing hypotheses, and they need to recognize the absence of or gaps in information. <p>
After interviewing intelligence analysts about how they do their work, <a href="sui_references.html#pirolli05" title="P.&nbsp;Pirolli and
  S.K. Card.
The sensemaking process and leverage points for analyst technology as
  identified through cognitive task analysis.
In <i>Proceedings of the 2005 International Conference on Intelligence
  Analysis</i>, McClean, VA, May 2005.">Pirolli and Card, 2005</a> described the process as consisting of an information foraging loop consisting of seeking, filtering, reading, and extracting information, and a sensemaking loop consisting of iterative development of a mental model that best fits the information seen as well as what was known beforehand. <p>
<a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press.">O'Day and Jeffries, 1993</a> studied business analysts working with search intermediaries. They observed three main kinds of information seeking tasks: monitoring a well-known topic over time (such as researching competitors' activities each quarter), following a plan or stereotyped series of searches to achieve a particular goal (such as keeping up to date on good business practices), and exploring a topic in an undirected fashion (as when getting to know an unfamiliar industry). Information seeking was only one part of the full work process their subjects were engaged in. In between searching sessions many different kinds of work was done with the retrieved information, including reading and annotating (<a href="sui_references.html#ohara97" title="Kenton O'Hara and
  Abigail Sellen.
A comparison of reading paper and on-line documents.
In <i>Proceedings of the SIGCHI Conference on Human Factors in Computing
  Systems (CHI'97)</i>, Atlanta, GA, March 1997.">O'Hara and Sellen, 1997</a>) and analysis. <a href="sui_references.html#oday93" title="Vicki&nbsp;L. O'Day and
  Robin Jeffries.
Orienteering in an information landscape: how information seekers get from here
  to there.
In <i>Proceedings of the INTERCHI Conference on Human Factors in Computing
  Systems (CHI'93)</i>, Amsterdam, April 1993. IOS Press.">O'Day and Jeffries, 1993</a> examined the analysis steps in more detail, finding that 80&#37; of this work fell into six main types: finding trends, making comparisons, aggregation, identifying a critical subset, assessing, and interpreting. The remainder consisted of cross-referencing, summarizing, finding evocative visualizations for reports, and miscellaneous activities. <p>
The standard Web search interface does not do a good job of supporting the sensemaking process. <a href="sui_references.html#patterson2001pvc" title="ES&nbsp;Patterson, EM&nbsp;Roth, and DD&nbsp;Woods.
Predicting Vulnerabilities in Computer-Supported Inferential Analysis under
  Data Overload.
<i>Cognition, Technology &amp; Work</i>, 3(4):224&ndash;237, 2001.">Patterson et&nbsp;al.,   2001</a> also reported on a controlled observational study in which 10 professional intelligence analysts performed an information gathering and analysis task. (The analysts were asked to determine the causes and impacts of the failure of the first flight of the Ariane 501 rocket launcher in 1996.) They were given 3--4 hours to complete the task, a collection of 2,000 documents, 9 of which had been pre-determined to be &#8220;high-profit&#8221; (of high topical relevancy and high utility for analyzing the event), and a &#8220;baseline&#8221; toolset that supported keyword queries, browsing articles by dates and titles sorted by relevance or date, and cutting and pasting of selected portions of documents to a text editor. <p>
The resulting reports were judged in terms of quality and accuracy; the better reports were defined as those whose authors found high-profit documents. The overall characteristic that distinguished analysts who discovered high-profit documents from those who did not was the persistence of the analysts; those who read more documents and spent more time on the task did better than those who did not. A similar result was found in another intelligence analysis study by <a href="sui_references.html#jonker2005itt" title="D.&nbsp;Jonker,
  W.&nbsp;Wright, D.&nbsp;Schroh, P.&nbsp;Proulx, and B.&nbsp;Cort.
Information Triage with TRIST.
<i>Proceedings of the International Conference on Intelligence
  Analysis</i>, 2005.">Jonker et&nbsp;al., 2005</a>. <p>
<div id="index_intelligence analysts_2"></div>
<p>
In the same vein, <a href="sui_references.html#tabatabai2005ean" title="D.&nbsp;Tabatabai and B.M. Shore.
How experts and novices search the Web.
<i>Library &amp; Information Science Research</i>, 27(2):222&ndash;248,
  2005.">Tabatabai and Shore,   2005</a> found that expert searchers were more patient than novices, and this, along with a positive attitude, led to better search outcomes. Factors that did <i> not</i> predict success included the kinds of queries issued, the percentage of retrieved documents that were of high-profit in the results, and the number of years of experience of the analysts (which ranged from 7--14 years). Nevertheless, it is likely that interfaces designed to support the sensemaking task directly could lead to improvements for users of all backgrounds. Chapter <a href="sui_ch7_search_process_tools.html"><b>7</b></a> discusses user interfaces to support the sensemaking process explicitly. <p>
<div id="index_expert searchers_3"></div>
<div id="index_novice searchers_3"></div>
<div id="index_sensemaking_3"></div>
<p>
</div> <!-- end div section -->
<div class="section" id="section_3.7"><h2>3.7: Information Needs and Query Intent</h2>
<p>
<div id="index_information needs_2"></div>
<p>
Information seeking encompasses a broad range of information needs, from focused fact finding to exploratory browsing (<a href="sui_references.html#sutcliffe1998" title="A.G.
  Sutcliffe and M.&nbsp;Ennis.
Towards a cognitive theory of information retrieval.
<i>Interacting with Computers</i>, 10:321&ndash;351, 1998.">Sutcliffe and Ennis, 1998</a>). People have different search needs at different times and in different contexts. Search problems span the spectrum from looking up a fact such as &#8220;What is the typical height of an adult male giraffe?&#8221; to building up knowledge about a topic, such as &#8220;What shall we do during our vacation in Barcelona?,&#8221; to browsing collections, such as art museum images, to supporting ground-breaking scientific research, such as synthesizing the literature to help determine the cause of Raynaud's disease. <a href="sui_references.html#shneiderman08" title="Ben Shneiderman.
Personal Communication, 2008.
December.">Shneiderman, 2008</a> makes a distinction between &#8220;1-minute&#8221; search and &#8220;1-week to 1-month search&#8221;, reflecting the difference between a fast, passing question and a longer-term information need. <p>
The term <i> information need</i> is used throughout the search interface literature. <a href="sui_references.html#wilson1981ous" title="T.D. Wilson.
On user studies and information needs.
<i>Journal of Librarianship</i>, 37(1):3&ndash;15, 1981.
Available at http://informationr.net/tdw/publ/papers/1981infoneeds.htm.">Wilson, 1981</a> points out the problematic nature of attempting to define it, but does propose the following: <p>
<blockquote>
&#8220;[W]hen we talk of users' &#8220;information needs&#8221; we should not have in mind some conception of a fundamental, innate, cognitive or emotional &#8220;need&#8221; for information, but a conception of in-formation (facts, data, opinion, advice) as one means towards the end of satisfying such fundamental needs.&#8221; </blockquote>
<p>
Others have defined information need in terms of the search system. <a href="sui_references.html#shneiderman1997csu" title="B.&nbsp;Shneiderman, D.&nbsp;Byrd, and WB&nbsp;Croft.
Clarifying Search: A User-Interface Framework for Text Searches.
<i>DL Magazine</i>, January 1997.">Shneiderman et&nbsp;al.,   1997</a> define it as: <p>
<blockquote>
&#8220;[T]he perceived need for information that leads to someone using an information retrieval system in the first place.&#8221; </blockquote>
<p>
In response to this, <a href="sui_references.html#dearman2008edi" title="D.&nbsp;Dearman,
  M.&nbsp;Kellar, and K.N. Truong.
An examination of daily information needs and sharing opportunities.
In <i>Proceedings of the ACM 2008 conference on Computer Supported
  Cooperative Work (CSCW'08)</i>, pages 679&ndash;688. ACM New York, NY, USA,
  2008.">Dearman et&nbsp;al., 2008</a> define information need as: <p>
<blockquote>
&#8220;[W]hen an individual requires any information to complete a task, or to satisfy the curiosity of the mind, independent of the method used to address the need, and regardless of whether the need is satisfied or not.&#8221; </blockquote>
<p>
<p>
A number of researchers have attempted to taxonomize and tally the types of information needs that searchers have, and to categorize and characterize individual queries. Some of these efforts made use of surveys and questionnaires, others used in-person observation, and still others used query log analysis as a way to acquire a large-scale, representative understanding of the user population. The resulting query classifications are not necessarily ideal, but because they are often referred to, and because the authors of the studies computed relative frequency of occurrence of the entries in the taxonomies, it is useful to look at their findings in detail. There have also been attempts to automatically classify queries according to the underlying intent, also discussed below. Today, web search engines are incorporating query classification into their ranking analysis. <p>
<div id="index_query intent_1"></div>
<div id="index_query logs_3"></div>
<div id="index_query taxonomies_1"></div>
<p>
<div class="subsection" id="subsection_3.7.1"><h3>3.7.1: Web Log-based Query Taxonomies</h3>
<p>
<p>
Prior to the Web, search engine designers could safely assume that searchers had an informational goal in mind (<a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>, <a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004."> Rose and Levinson, 2004</a>). This was due in part to the limited population of searchers (primarily students, legal analysts, scientific researchers, business analysts) and to the kind of data that could be searched (newswire, legal cases, journal article abstracts). The queries to these systems were often long, or contained Boolean operators. Users had to carefully craft their queries, because they often paid by the minute, and careless query formulation was expensive. <p>
As the Web developed, it became the case that not only were queries shorter and simpler, but the types of information available were quite different. As opposed to legal cases or academic papers, the Web included information about organizations (where they are located, what their phone numbers are, what their business is), products, and individuals. Correspondingly, the underlying goals of user queries were often quite different than in the older systems. In an attempt to demonstrate how information needs for Web search differ from the assumptions of pre-web information retrieval systems, <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a> created a taxonomy of Web search goals. He then estimated the frequency of such goals by a combination of an online survey (3,200 responses, 10&#37; response rate) and a manual analysis of 1,000 query from the AltaVista query logs. The three types of &#8220;need behind the query&#8221; that he identified were: <p>
<div id="index_AltaVista_3"></div>
<p>
<ul>
<li> <i> Navigational</i> : The immediate intent is to reach a particular site (24.5&#37; survey, 20&#37; query log). <li> <i> Informational</i> : The intent is to acquire some information assumed to be present on one or more Web pages (39&#37; survey, 48&#37; query log). <li> <i> Transactional</i> : The intent is to perform some web-mediated activity (36&#37; survey, 30&#37; query log). </ul>
<p>
This taxonomy has been heavily influential in discussions of query types on the Web. <p>
<div id="index_navigational queries_1"></div>
<div id="index_informational queries_1"></div>
<div id="index_transactional queries_1"></div>
<p>
<a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004.">Rose and Levinson, 2004</a> followed up on <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>'s work, again using Web query logs, but developing a taxonomy that differed somewhat from <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a> 's. They retained the navigational and informational categories, but noted that much of what happens on the Web is the acquisition and consumption of online resources, such as song lyrics, knitting patterns, and software downloads. Thus they replace <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>'s transactions category with a broader category of <i> resources</i>, meaning information artifacts that users consume in some manner other than simply reading for information (although they somewhat confusingly categorize shopping queries under the informational category). They also introduced subcategories for the three main categories, including the interesting subcategory of <i> advice seeking</i> (which has become popular on human question answering sites; see Chapter <a href="sui_ch12_emerging.html"><b>12</b></a>). <p>
<div id="index_advice seeking queries_1"></div>
<p>
<div id="index_resource queries_1"></div>
<p>
<a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004.">Rose and Levinson, 2004</a> manually classified a set of 1,500 AltaVista search engine log queries. For two sets of 500 queries, the labeler saw just the query and the retrieved documents; for the third set the labeler also saw which item(s) the searcher clicked on. They found that the classifications that used the extra information about clickthrough did not significantly change the proportions of assignments to each category. However, because they did not directly compare judgements with and without click information on the same queries, this is only weak evidence that query plus retrieved documents is sufficient to classify query intent. (To bolster their claim, a similar result was found by <a href="sui_references.html#shen2005qcu" title="D.&nbsp;Shen, R.&nbsp;Pan,
  J.T. Sun, J.J. Pan, K.&nbsp;Wu, J.&nbsp;Yin, and Q.&nbsp;Yang.
Q2C@UST: our winning solution to query classification in KDDCUP 2005.
<i>ACM SIGKDD Explorations Newsletter</i>, 7(2):100&ndash;110, 2005.">Shen et&nbsp;al., 2005a</a>, who developed an algorithm to effectively classify queries into subject-matter topics without using clickthrough data.) <p>
<a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004.">Rose and Levinson, 2004</a> found a smaller proportion of navigational queries than did <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a> (an average of 13&#37; compared to his average of 22&#37;), but this difference may have to do with differences in sampling and search engine user bases for the two studies. They also found that informational queries were about 61&#37; of the information needs, a much higher proportion than <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>'s average of 45&#37;. <p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.7.2"><h3>3.7.2: Web Log-based Query Topic Classification</h3>
<p>
Queries from Web query logs can be classified according to the <i> topic</i> of the query, independent of the type of information need. For example, a search involving the topic of weather can consist of the simple information need of looking at today's forecast, or the rich and complex information need of studying meteorology. <p>
Over many years, Spink and Jansen et al. (<a href="sui_references.html#jansen2006" title="B.J. Jansen and
  A.&nbsp;Spink.
How are we searching the World Wide Web? A comparison of nine search engine
  transaction logs.
<i>Information Processing and Management</i>, 42(1):248&ndash;263, 2006.">Jansen and Spink, 2006</a>, <a href="sui_references.html#jansen2005tca" title="B.J. Jansen,
  A.&nbsp;Spink, and J.O. Pedersen.
A Temporal Comparison Of Altavista Web Searching.
<i>Journal Of The American Society For Information Science And
  Technology</i>, 56(6):559&ndash;570, 2005."> Jansen et&nbsp;al., 2005</a>, <a href="sui_references.html#jansen2007wsi" title="B.J. Jansen,
  A.&nbsp;Spink, and S.&nbsp;Koshman.
Web searcher interaction with the Dogpile.com metasearch engine.
<i>Journal of the American Society for Information Science and
  Technology</i>, 58(5):744&ndash;755, 2007."> Jansen et&nbsp;al., 2007b</a>, <a href="sui_references.html#spink2002scw" title="A.&nbsp;Spink, B.J.
  Jansen, D.&nbsp;Wolfram, and T.&nbsp;Saracevic.
From E-Sex to E-Commerce: Web Search Changes.
<i>IEEE Computer</i>, 35(3):107&ndash;109, 2002."> Spink et&nbsp;al., 2002</a>) have manually analyzed samples of query logs to track a number of different trends. One of the most notable is the change in topic mix. In one article, they compared a manual analysis on AltaVista logs from 1997 with queries from the Dogpile metasearch engine in 2005 (<a href="sui_references.html#jansen2007wsi" title="B.J. Jansen,
  A.&nbsp;Spink, and S.&nbsp;Koshman.
Web searcher interaction with the Dogpile.com metasearch engine.
<i>Journal of the American Society for Information Science and
  Technology</i>, 58(5):744&ndash;755, 2007.">Jansen et&nbsp;al., 2007b</a>). They found that queries relating to sex and pornography declined from 16.8&#37; in 1997 to just 3.6&#37; in 2005. Commerce-related queries now dominate the query logs, claiming 30.4&#37; in this study, up from 13.3&#37; in 1997 (<a href="sui_references.html#spink2002scw" title="A.&nbsp;Spink, B.J.
  Jansen, D.&nbsp;Wolfram, and T.&nbsp;Saracevic.
From E-Sex to E-Commerce: Web Search Changes.
<i>IEEE Computer</i>, 35(3):107&ndash;109, 2002.">Spink et&nbsp;al., 2002</a>) (see Table <a href="#table_3.1"><b>3.1</b></a>). <p>
<div id="index_AltaVista_4"></div>
<div id="index_Dogpile_1"></div>
<div id="index_pornography queries_1"></div>
<p>
<div class="table" id = "table_3.1"><blockquote> <TABLE class="centered"> <TR><TH ALIGN="LEFT">Rank</TD> <TH ALIGN="LEFT">Topic</TD> <TH ALIGN="RIGHT">Number</TD> <TH ALIGN="RIGHT">Percent</TD> </TR> <TR><TD ALIGN="LEFT">1</TD> <TD ALIGN="LEFT">Commerce, travel, employment, or economy</TD> <TD ALIGN="RIGHT">761</TD> <TD ALIGN="RIGHT">30.4</TD> </TR> <TR><TD ALIGN="LEFT">2</TD> <TD ALIGN="LEFT">People, places, or things</TD> <TD ALIGN="RIGHT">402</TD> <TD ALIGN="RIGHT">16.0</TD> </TR> <TR><TD ALIGN="LEFT">3</TD> <TD ALIGN="LEFT">Unknown or other</TD> <TD ALIGN="RIGHT">331</TD> <TD ALIGN="RIGHT">13.2</TD> </TR> <TR><TD ALIGN="LEFT">4</TD> <TD ALIGN="LEFT">Health or sciences</TD> <TD ALIGN="RIGHT">224</TD> <TD ALIGN="RIGHT">8.9</TD> </TR> <TR><TD ALIGN="LEFT">5</TD> <TD ALIGN="LEFT">Entertainment or recreation</TD> <TD ALIGN="RIGHT">177</TD> <TD ALIGN="RIGHT">7.0</TD> </TR> <TR><TD ALIGN="LEFT">6</TD> <TD ALIGN="LEFT">Computers or Internet</TD> <TD ALIGN="RIGHT">144</TD> <TD ALIGN="RIGHT">5.7</TD> </TR> <TR><TD ALIGN="LEFT">7</TD> <TD ALIGN="LEFT">Education or humanities</TD> <TD ALIGN="RIGHT">141</TD> <TD ALIGN="RIGHT">5.6</TD> </TR> <TR><TD ALIGN="LEFT">8</TD> <TD ALIGN="LEFT">Society, culture, ethnicity, or religion</TD> <TD ALIGN="RIGHT">119</TD> <TD ALIGN="RIGHT">4.7</TD> </TR> <TR><TD ALIGN="LEFT">9</TD> <TD ALIGN="LEFT">Sex or pornography</TD> <TD ALIGN="RIGHT">97</TD> <TD ALIGN="RIGHT">3.8</TD> </TR> <TR><TD ALIGN="LEFT">10</TD> <TD ALIGN="LEFT">Government or legal</TD> <TD ALIGN="RIGHT">90</TD> <TD ALIGN="RIGHT">3.6</TD> </TR> <TR><TD ALIGN="LEFT">11</TD> <TD ALIGN="LEFT">Arts</TD> <TD ALIGN="RIGHT">14</TD> <TD ALIGN="RIGHT">0.5</TD> </TR> </TABLE> <br /><div class="caption"> <b>Table 3.1</b> Topics manually assigned to 2,500 queries against the Dogpile metasearch engine in 2005 (<a href="sui_references.html#jansen2007wsi" title="B.J. Jansen,
  A.&nbsp;Spink, and S.&nbsp;Koshman.
Web searcher interaction with the Dogpile.com metasearch engine.
<i>Journal of the American Society for Information Science and
  Technology</i>, 58(5):744&ndash;755, 2007.">Jansen et&nbsp;al., 2007b</a>). 
</div><!-- end div caption --></blockquote></div> <!-- end div table --><p>
<p>
<p>
As an alternative to manual classification of query topics, <a href="sui_references.html#shen2005qcu" title="D.&nbsp;Shen, R.&nbsp;Pan,
  J.T. Sun, J.J. Pan, K.&nbsp;Wu, J.&nbsp;Yin, and Q.&nbsp;Yang.
Q2C@UST: our winning solution to query classification in KDDCUP 2005.
<i>ACM SIGKDD Explorations Newsletter</i>, 7(2):100&ndash;110, 2005.">Shen et&nbsp;al., 2005a</a> described an algorithm for automatically classifying Web queries into a set of pre-defined topics. The main idea is to use a Web search engine to retrieve the top <i>n</i> results for a query, and then look at the categories that have been manually associated with those results in the past (using the Open Directory Project, ODP). They used a voting method to combine evidence from several measures, and returned the top scoring categories (up to five per query). Their results were quite strong, (an F-score of about 0.45 on 63 categories). Table <a href="#table_3.2"><b>3.2</b></a> shows the results for five arbitrarily chosen queries. Another approach to this problem is described by <a href="sui_references.html#pu2002scq" title="H.T. Pu, S.L. Chuang, and
  C.&nbsp;Yang.
Subject categorization of query terms for exploring Web users' search
  interests.
<i>Journal of the American Society for Information Science and
  Technology</i>, 53(8):617&ndash;630, 2002.">Pu et&nbsp;al., 2002</a>. <p>
<div id="index_Open Directory Project_1"></div>
<p>
More recently, <a href="sui_references.html#broder07" title="A.&nbsp;Broder,
  M.&nbsp;Fontoura, E.&nbsp;Gabrilovich, A.&nbsp;Joshi, V.&nbsp;Josifovski, and T.&nbsp;Zhang.
Robust classification of rare queries using web knowledge.
<i>Proceedings of the 30th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'07)</i>,
  2007.">Broder et&nbsp;al., 2007</a> presented a highly accurate method (around 0.7 F-score) for classifying short, rare queries into a taxonomy of 6,000 categories. Because rare or infrequent queries are approximately half of all queries, this is an important advance. Using a commercial taxonomy which contained many documents assigned to each category, they trained a set of text classifiers. Given a query, they retrieved the top <i>k</i> documents using a search engine, classified documents according to the text classifier, and then used a voting algorithm to determine which class(es) best categorize the query. <a href="sui_references.html#gauch2003obp" title="S.&nbsp;Gauch.
Ontology-based personalized search and browsing.
<i>Web Intelligence and Agent Systems</i>, 1(3):219&ndash;234, 2003.">Gauch, 2003</a> found that a similar approach worked well for creating profiles of user interests based on which documents they visited (see Chapter <a href="sui_ch9_personalization.html"><b>9</b></a>). <p>
<div class="table" id = "table_3.2"><blockquote> <TABLE> <TR><TH ALIGN="LEFT">Query</TD> <TH ALIGN="RIGHT">Top category</TD> <TH ALIGN="RIGHT">Second category</TD> </TR> <TR><TD ALIGN="LEFT">chat rooms</TD> <TD ALIGN="RIGHT">Computers/Internet</TD> <TD ALIGN="RIGHT">Online Community/Chat</TD> </TR> <TR><TD ALIGN="LEFT">lake michigan lodges</TD> <TD ALIGN="RIGHT">Info/Local amp; Regional</TD> <TD ALIGN="RIGHT">Living/Travel amp; Vacation</TD> </TR> <TR><TD ALIGN="LEFT">stephen hawking</TD> <TD ALIGN="RIGHT">Info/Science amp; Tech</TD> <TD ALIGN="RIGHT">Info/Arts amp; Humanities</TD> </TR> <TR><TD ALIGN="LEFT">dog shampoo</TD> <TD ALIGN="RIGHT">Shopping/Buying Guides</TD> <TD ALIGN="RIGHT">Living/Pets amp; Animals</TD> </TR> <TR><TD ALIGN="LEFT">text mining</TD> <TD ALIGN="RIGHT">Computers/Software</TD> <TD ALIGN="RIGHT">Information/Companies</TD> </TR> </TABLE> <br /><div class="caption"> <b>Table 3.2</b> Top two categories returned for five arbitrarily chosen queries submitted to the system of Q2C@UST (<a href="sui_references.html#shen2005qcu" title="D.&nbsp;Shen, R.&nbsp;Pan,
  J.T. Sun, J.J. Pan, K.&nbsp;Wu, J.&nbsp;Yin, and Q.&nbsp;Yang.
Q2C@UST: our winning solution to query classification in KDDCUP 2005.
<i>ACM SIGKDD Explorations Newsletter</i>, 7(2):100&ndash;110, 2005.">Shen et&nbsp;al., 2005a</a>). 
</div><!-- end div caption --></blockquote></div> <!-- end div table --><p>
<div id="index_query taxonomies_2"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.7.3"><h3>3.7.3: Web Log-based Analysis of Query Ambiguity</h3>
<p>
<div id="index_ambiguous queries_1"></div>
<p>
Ambiguous queries are those queries that can be understood as corresponding to two or more distinct meanings: a query on <b> apple</b>  may refer to the fruit or the computer manufacturer or the record label. A number of search interface ideas that are discussed in this book, although intended to be useful in a general way, turn out to be effective mainly for ambiguous queries (see Chapters <a href="sui_ch8_navigation_and_search.html"><b>8</b></a> and <a href="sui_ch9_personalization.html"><b>9</b></a>). For this reason, some researchers have tried to estimate what proportion of queries truly are ambiguous. <p>
One way to predict query ambiguity is to see what the diversity of clicks is for a given query. The thinking is that if users tend to click on the same set of links for a given query, that query indicates a single set of intentions, but if there is great diversity in the links clicked on, then the query is likely to be ambiguous either in meaning or in what user intentions it reflects. <p>
<div id="index_diversity_1"></div>
<p>
<a href="sui_references.html#wen2002qcu" title="J.-R. Wen, J.Y. Nie,
  and H.J. Zhang.
Query clustering using user logs.
<i>ACM Transactions on Information Systems (TOIS)</i>, 20(1):59&ndash;81,
  2002.">Wen et&nbsp;al., 2002</a> did a clickthrough analysis of queries to an online encyclopedia, and found that identical query terms produced nearly identical clicks. They speculated that users were self-disambiguating by their choice of terms. <a href="sui_references.html#song2007" title="Ruihau Song, Zhenziao
  Luo, Ji-Rong Wen, Yong Yu, and Hsiao-Wuen Hon.
Identifying ambiguous queries in web search.
<i>Proceedings of the 16th International Conference on World Wide Web
  (WWW'07) Poster Session</i>, 2007.">Song et&nbsp;al., 2007</a> described an algorithm for estimating how many queries in a query log are ambiguous. They had 5 judges label 60 queries as either ambiguous or not, achieving 90&#37; agreement. They then used a search engine to retrieve the top <i>n</i> documents for each query, and categorized those documents into a pre-defined ontology using the technique of <a href="sui_references.html#shen2005qcu" title="D.&nbsp;Shen, R.&nbsp;Pan,
  J.T. Sun, J.J. Pan, K.&nbsp;Wu, J.&nbsp;Yin, and Q.&nbsp;Yang.
Q2C@UST: our winning solution to query classification in KDDCUP 2005.
<i>ACM SIGKDD Explorations Newsletter</i>, 7(2):100&ndash;110, 2005.">Shen et&nbsp;al., 2005a</a>. If the documents returned for a query fell into multiple categories, they considered that query to be ambiguous. Using this approach, they achieved 87&#37; accuracy on a test set of 253 queries (using cross-validation). Applying this algorithm to a larger sample, they estimated that that sample contained only 16&#37; ambiguous queries. <p>
<div id="index_clickthrough_1"></div>
<div id="index_ambiguous queries_2"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.7.4"><h3>3.7.4: Web Log-based Analysis of Re-access Patterns</h3>
<p>
<div id="index_revisitation_2"></div>
<p>
Many searches are characterized by people re-accessing information that they have seen in the past (<a href="sui_references.html#jones2001kft" title="W.&nbsp;Jones, H.&nbsp;Bruce,
  and S.&nbsp;Dumais.
Keeping Found Things Found On The Web.
<i>Proceedings of the Tenth International Conference on Information and
  Knowledge Management (CIKM'01)</i>, pages 119&ndash;126, 2001.">Jones et&nbsp;al., 2001</a>, <a href="sui_references.html#jones2002oft" title="W.&nbsp;Jones,
  S.&nbsp;Dumais, and H.&nbsp;Bruce.
Once Found, What Then? A Study Of Keeping Behaviors In The Personal Use Of
  Web Information.
<i>Proceedings Of The American Society For Information Science And
  Technology</i>, 39(1):391&ndash;402, 2002."> Jones et&nbsp;al., 2002</a>, <a href="sui_references.html#aula2005isa" title="A.&nbsp;Aula, N.&nbsp;Jhaveri,
  and M.&nbsp;K&auml;ki.
Information search and re-access strategies of experienced web users.
<i>Proceedings of the 14th International Conference on World Wide Web
  (WWW'05)</i>, pages 583&ndash;592, 2005."> Aula et&nbsp;al., 2005a</a>). This can be accomplished by saving previously visited information via Web browser bookmarks or using bookmarking Web sites such as delicious.com. The observations of <a href="sui_references.html#teevan2004pse" title="J.&nbsp;Teevan,
  C.&nbsp;Alvarado, M.S. Ackerman, and D.R. Karger.
The perfect search engine is not enough: a study of orienteering behavior in
  directed search.
<i>Proceedings of the 27th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'04)</i>, pages
  415&ndash;422, 2004.">Teevan et&nbsp;al., 2004</a> suggested that searchers often navigate to Web pages they have visited in the past rather than issuing a search engine query. However, there is also ample evidence that people use search engines as re-finding instruments. In another study, <a href="sui_references.html#teevan07ir" title="J.&nbsp;Teevan, E.&nbsp;Adar,
  R.&nbsp;Jones, and M.A.S. Potts.
Information re-retrieval: repeat queries in yahoo's logs.
In <i>Proceedings of the 30th Annual International ACM SIGIR Conference on
  Research and development in information retrieval (SIGIR'07)</i>, pages
  151&ndash;158. ACM Press, 2007.">Teevan et&nbsp;al., 2007</a> examined 13,000 queries and 22,000 search result clicks from a query log, and found that 40&#37; of the queries led to a click on a result that the same user had clicked on in a past search session. <p>
As is discussed in Chapter <a href="sui_ch9_personalization.html"><b>9</b></a>, researchers have made use of query log behavior to try to improve ranking algorithms, as well as to attempt to predict individual user's behavior and preferences based on past actions. <p>
<p>
<div id="index_query intent_2"></div>
<div id="index_query logs_4"></div>
<p>
</div> <!-- end div subsection -->
<div class="subsection" id="subsection_3.7.5"><h3>3.7.5: Classifying Observed Search Behavior</h3>
<p>
The previous section describes the classification of information needs based on query log analysis. Another approach is to observe people more directly and classify their search activities more broadly. <p>
<p>
<a href="sui_references.html#kellar2006" title="M.&nbsp;Kellar,
  C.&nbsp;Watters, and M.&nbsp;Shepherd.
A Goal-based Classification of Web Information Tasks.
<i>Proceedings of American Society for Information Science and Technology
  Conference</i>, 2006.">Kellar et&nbsp;al., 2006a</a> collected statistics for self-reported task type frequency for Web browser users. Twenty-one university student participants used an instrumented Web browser that recorded their actions for one week, resulting in 1,192 task sessions (13,500 web pages). Participants were asked to label every Web page access with a task type from the taxonomy. The authors carefully developed a task type taxonomy to remove confusion about their meaning and ensured that the study participants would be able to consistently assign labels. The five main categories were: <p>
<p>
<ul>
<li> <i> Fact Finding:</i> Looking for specific facts or pieces of information; usually short lived tasks, completed over a single session. Examples were looking, searching or checking for tomorrow's weather, a recipe, a file (for download), a research paper, definitions, help with a game, java documentation, song lyrics, the average mass of a bullet. <p>
<li> <i> Information Gathering:</i> A task that involves the collection of information, often from multiple sources. Can take place over multiple days. It is not always clear when the task is completed and there is not always one specific answer. Examples were looking for or researching information on a new laptop, conferences, new wireless card, making a resume, papers on policy-based network, renting a car, risk analysis, summer school courses. <p>
<li> <i> Browsing:</i> A serendipitous task where Web pages are visited with no particular goal other than entertainment or to &#8220;see what's new.&#8221; Sometimes this is done as part of a daily routine. Examples were looking for or reading blogs, browsing a Web site, the news, listening to music, movie trailers, updates on movie Web site, comics, wasting time. <p>
<li> <i> Transactions:</i> Online actions. Examples were checking or acting on email, banking, applying for a credit card, blogging, logging diet and exercise information, online shopping, sending a greeting, taking part in a survey. <p>
<li> <i> Other:</i> Other activities, such as Web page maintenance. <p>
</ul>
<p>
<p>
<div id="index_fact finding_1"></div>
<div id="index_information gathering_1"></div>
<div id="index_transactional queries_2"></div>
<div id="index_navigation_5"></div>
<p>
Table <a href="#table_3.3"><b>3.3</b></a> shows the frequency of activities according to the taxonomy. Nearly half the Web usages were attributable to online transactions, primarily email usage. Fact finding constituted about 18&#37; of the tasks, and more than 55&#37; of these were repeat activities. Repeated fact finding often had a monitoring aspect, such as checking the weather forecast daily. Information gathering was about 13&#37; of the activities; many stretched over several days including one that lasted six days (researching graduate schools to apply to). Browsing constituted 19&#37; of the tasks and included news reading, reading blogs, visiting gaming-related sites, and reading entertainment-related Web pages. There was evidence that monitoring occurs with different frequencies across different tasks. <p>
<p>
<div class="table" id = "table_3.3"><blockquote> <TABLE> <TR><TH ALIGN="LEFT">Task</TD> <TH ALIGN="RIGHT">% of total Web use</TD> <TH ALIGN="RIGHT">% that were repeats</TD> </TR> <TR><TD ALIGN="LEFT">Fact Finding</TD> <TD ALIGN="RIGHT">18.3</TD> <TD ALIGN="RIGHT">55.5</TD> </TR> <TR><TD ALIGN="LEFT">Information Gathering</TD> <TD ALIGN="RIGHT">13.5</TD> <TD ALIGN="RIGHT">58.5</TD> </TR> <TR><TD ALIGN="LEFT">Browsing</TD> <TD ALIGN="RIGHT">19.9</TD> <TD ALIGN="RIGHT">84.4</TD> </TR> <TR><TD ALIGN="LEFT">Transactions</TD> <TD ALIGN="RIGHT">46.7</TD> <TD ALIGN="RIGHT">95.2</TD> </TR> <TR><TD ALIGN="LEFT">Other</TD> <TD ALIGN="RIGHT">1.7</TD> <TD ALIGN="RIGHT">-</TD> </TR> </TABLE> <br /><div class="caption"> <b>Table 3.3</b> Web page task usage statistics from a study by (<a href="sui_references.html#kellar2006" title="M.&nbsp;Kellar,
  C.&nbsp;Watters, and M.&nbsp;Shepherd.
A Goal-based Classification of Web Information Tasks.
<i>Proceedings of American Society for Information Science and Technology
  Conference</i>, 2006.">Kellar et&nbsp;al., 2006a</a>). 
</div><!-- end div caption --></blockquote></div> <!-- end div table --><p>
Unfortunately, there are problems with attempting to compare these results to the query log studies described above. These are broader task classifications, so a subgoal like find the home page of an e-commerce site would be subsumed into online shopping. Thus, statistics of the more fine-grained activities seen at the query level (e.g., navigational queries) are not categorized as such. The tasks described correspond to all Web pages viewed, as opposed to only those examined in response to a search. And finally, many of the categorizations differ from both <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a>'s and <a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004.">Rose and Levinson, 2004</a> 's. For example, in <a href="sui_references.html#kellar2006" title="M.&nbsp;Kellar,
  C.&nbsp;Watters, and M.&nbsp;Shepherd.
A Goal-based Classification of Web Information Tasks.
<i>Proceedings of American Society for Information Science and Technology
  Conference</i>, 2006.">Kellar et&nbsp;al., 2006a</a> accessing information about iPod prices is classified as information gathering, while the online shopping part of the process (potentially including the price comparison component) is categorized as transactional. <a href="sui_references.html#rose2004uug" title="D.E. Rose and
  D.&nbsp;Levinson.
Understanding User Goals In Web Search.
<i>Proceedings of the 13th International Conference on World Wide Web
  (WWW'04)</i>, pages 13&ndash;19, 2004.">Rose and Levinson, 2004</a> would list the search for the shopping information under informational and <a href="sui_references.html#broder2002tws" title="A.&nbsp;Broder.
A taxonomy of web search.
<i>SIGIR Forum</i>, 36(2):3&ndash;10, 2002.">Broder, 2002</a> would classify it as transactional. <p>
<div id="index_information needs_3"></div>
<p>
</div> <!-- end div subsection -->
</div> <!-- end div section -->
<div class="section" id="section_3.8"><h2>3.8: Conclusions</h2>
<p>
This chapter has summarized the major theoretical models of information seeking, including: <p>
<ul>
<li> The Standard model, <li> The Cognitive model, <li> The Dynamic (Berry-picking) model, <li> Information seeking in stages, <li> Information seeking as a strategic process, including <ul>
<li> Strategies as sequences of tactics, <li> Cost structure analysis and foraging theory, <li> Browsing versus search, <li> Orienteering and other incremental strategies, and </ul>
<li> Sensemaking. </ul>
<p>
The chapter also defined the notion of information need and summarized research on inferring the user's information need from records of their queries, and presented the major query intent taxonomies that are in common use today. These taxomonies are not comprehensive; they do not, for example, distinguish between ad hoc queries (spur of the moment, or one-time) and standing queries (an information need that a user is continually interested in), but they are referred to heavily in the literature and have helped shape thinking about query intent. <p>
In the chapters that follow, an attempt is made to link the various interfaces designs and issues to aspects of these theoretical models. A potentially fruitful strategy for designing new search interfaces is to notice the gaps in support of these models, or the aspects that are not well-served in current designs. Additionally, many types of information needs are not currently supported well in search algorithms and interfaces. The next breakthrough in search interface design could arise from finding new techniques that better support how people are naturally inclined to conduct their searches. <p>
<div id="index_information seeking_2"></div>
<p>
</div> <!-- end div section -->
</div> <!-- end div chapter -->
<div class="nextnav"><div class="leftnext"><a href="sui_ch2_evaluation.html"><strong> << Previous: </strong></a>&nbsp;(Ch. 2) </div><!-- div leftnext -->
<div class="rightnext">(Ch. 4)&nbsp;<a href="sui_ch4_query_specification.html"><strong>: Next >></strong></a></div><!-- div rightnext --><div class="middle"><a href="#chapter_3">Top</a> (Ch. 3)</a></div><!-- middle --></div><!-- div nextnav -->
</div><!-- div col --></div><!-- maincol --><div id="navcol"><div id="sidebar"><ul>

<form action="sphider/search.php" method="get">
<input type="text" name="query" id="query" class="querybox" size="20" value="" action="sphider/include/js_suggest/suggest.php" columns=2 autocomplete="off" delay="700">
<input type="submit" value="Search">
<input type="hidden" name="search" value="1">
</form>

<li> <h2>Chapter Contents</h2><ul><li><a href="#section_3.1"> 3.1: The Standard Model of Information Seeking</a></li>
<li><a href="#section_3.2"> 3.2: Cognitive Models of Information Seeking</a></li>
<li><a href="#section_3.3"> 3.3: The Dynamic (Berry-Picking) Model</a></li>
<li><a href="#section_3.4"> 3.4: Information Seeking in Stages</a></li>
<li><a href="#section_3.5"> 3.5: Information Seeking as a Strategic Process</a></li>
<li><a href="#section_3.6"> 3.6: Sensemaking: Search as Part of a Larger Process</a></li>
<li><a href="#section_3.7"> 3.7: Information Needs and Query Intent</a></li>
<li><a href="#section_3.8"> 3.8: Conclusions</a></li>
</ul>
<li><h2>Book Contents</h2><ul><li><a href="sui_ch0_preface.html">0: Preface</a></li>
<li><a href="sui_ch1_design.html">1: Design of Search User Interfaces</a></li>
<li><a href="sui_ch2_evaluation.html">2: Evaluation of Search User Interfaces</a></li>
<li><a href="sui_ch3_models_of_information_seeking.html">3: Models of the Information Seeking Process</a></li>
<li><a href="sui_ch4_query_specification.html">4: Query Specification</a></li>
<li><a href="sui_ch5_retrieval_results.html">5: Presentation of Search Results</a></li>
<li><a href="sui_ch6_reformulation.html">6: Query Reformulation</a></li>
<li><a href="sui_ch7_search_process_tools.html">7: Supporting the Search Process</a></li>
<li><a href="sui_ch8_navigation_and_search.html">8: Integrating Navigation with Search</a></li>
<li><a href="sui_ch9_personalization.html">9: Personalization in Search</a></li>
<li><a href="sui_ch10_visualization.html">10: Information Visualization for Search Interfaces</a></li>
<li><a href="sui_ch11_text_analysis_visualization.html">11: Information Visualization for Text Analysis</a></li>
<li><a href="sui_ch12_emerging.html">12: Emerging Trends in Search Interfaces</a></li>
<li><a href="sui_references.html">References</a></li><li><a href="sui_index.html">Index</a></li></ul>
<li><h2>Buy the Book</h2><ul><li>(Available Sept '09)<li><a href="http://www.amazon.com/Search-User-Interfaces-Marti-Hearst/dp/0521113792/ref=sr_1_1?ie=UTF8&s=books&qid=\
1244721779&sr=8-1">Amazon.com</li><li><a href="http://www.cambridge.org/us/catalogue/catalogue.asp?isbn=9780521113793"> Cambridge University Press</a></li></ul><li><h2>Comment</h2><a href="http://www.searchuserinterfaces.com/blog/2009/06/comments-on-chapter-3">View and Write Comments on this Chapter</a></li></ul></div><!-- sidebar --></div><!-- navcol --><div class="footer">Copyright &copy; 2009 by Marti A. Hearst.</div></div><!-- div footer --></div><!-- div container -->
</body></html>
