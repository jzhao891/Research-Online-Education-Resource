<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0071)http://telemat.det.unifi.it/book/2001/wchange/download/stem_porter.html -->
<!-- saved from url=(0051)http://www.omsee.com/developer/docs/porterstem.html --><HTML><HEAD><TITLE>Porter stemming algorithm</TITLE>
<META http-equiv=Content-Type content="text/html; charset=windows-1252">
<META content="MSHTML 6.00.2712.300" name=GENERATOR></HEAD>
<BODY bgColor=white>
<H1>
<CENTER>An algorithm for suffix stripping</H1></CENTER><BR>
<CENTER>M.F.Porter</CENTER>
<CENTER>1980</CENTER><BR>Originally published in <I>Program</I>, <B>14</B> no. 
3, pp 130-137, July 1980. 
<P>
<H2>1. Introduction</H2>Removing suffixes by automatic means is an operation 
which is especially useful in the field of information retrieval. In a typical 
IR environment, one has a collection of documents, each described by the words 
in the document title and possibly by words in the document abstract. Ignoring 
the issue of precisely where the words originate, we can say that a document is 
represented by a vetor of words, or <I>terms</I>. Terms with a common stem will 
usually have similar meanings, for example: <PRE>        CONNECT
        CONNECTED
        CONNECTING
        CONNECTION
        CONNECTIONS
</PRE>Frequently, the performance of an IR system will be improved if term 
groups such as this are conflated into a single term. This may be done by 
removal of the various suffixes -ED, -ING, -ION, IONS to leave the single term 
CONNECT. In addition, the suffix stripping process will reduce the total number 
of terms in the IR system, and hence reduce the size and complexity of the data 
in the system, which is always advantageous. 
<P>Many strategies for suffix stripping have been reported in the 
literature.<SUP>(e.g. 1-6)</SUP> The nature of the task will vary considerably 
depending on whether a stem dictionary is being used, whether a suffix list is 
being used, and of course on the purpose for which the suffix stripping is being 
done. Assuming that one is not making use of a stem dictionary, and that the 
purpose of the task is to improve IR performance, the suffix stripping program 
will usually be given an explicit list of siffixes, and, with each suffix, the 
criterion under which it may be removed from a word to leave a valid stem. This 
is the approach adopted here. The main merits of the present program are that it 
is small (less than 400 lines of BCPL), fast (it will process a vocabulary of 
10,000 different words in about 8.1 seconds on the IBM 370/165 at Cambridge 
University), and reasonably simple. At any rate, it is simple enough to be 
described in full as an algorithm in this paper. (The present version in BCPL is 
freely available from the author. BCPL is itself available on a wide range of 
different computers, but anyone wishing to use the program should have little 
difficulty in coding it up in other programming languages.) Given the speed of 
the program, it would be quite realistic to apply it to every word in a large 
file of continuous text, although for historical reasons we have found it 
convenient to apply it only to relatively small vocabulary lists derived from 
continuous text files. 
<P>In any suffix stripping program for IR work, two points must be borne in 
mind. Firstly, the suffixes are being removed simply to improve IR performance, 
and not as a linguistic exercise. This means that it would not be at all obvious 
under what circumstances a suffix should be removed, even if we could exactly 
determine the suffixes of a word by automatic means. 
<P>Perhaps the best criterion for removing suffixes from two words W1 and W2 to 
produce a single stem S, is to say that we do so if there appears to be no 
difference between the two statements `a document is about W1' and `a document 
is about W2'. So if W1=`CONNECTION' and W2=`CONNECTIONS' it seems very 
reasonable to conflate them to a single stem. But if W1=`RELATE' and 
W2=`RELATIVITY' it seems perhaps unreasonable, especially if the document 
collection is concerned with theoretical physics. (It should perhaps be added 
that RELATE and RELATIVITY <I>are</I> conflated together in the algorithm 
described here.) Between these two extremes there is a continuum of different 
cases, and given two terms W1 and W2, there will be some variation in opinion as 
to whether they should be conflated, just as there is with deciding the 
relevance of some document to a query. The evaluation of the worth of a suffix 
stripping system is correspondingly difficult. 
<P>The second point is that with the approach adopted here, i.e. the use of a 
suffix list with various rules, the success rate for the suffix stripping will 
be significantly less than 100% irrespective of how the process is evaluated. 
For example, if SAND and SANDER get conflated, so most probably will WAND and 
WANDER. The error here is that the -ER of WANDER has been treated as a suffix 
when in fact it is part of the stem. Equally, a suffix may completely alter the 
meaning of a word, in which case its removal is unhelpful. PROBE and PROBATE for 
example, have quite distinct meanings in modern English. (In fact these would 
not be conflated in our present algorithm.) There comes a stage in the 
development of a suffix stripping program where the addition of more rules to 
increase the performance in one area of the vocabulary causes an equal 
degradation of performance elsewhere. Unless this phenomenon is noticed in time, 
it is very easy for the program to become much more complex than is really 
necessary. It is also easy to give undue emphasis to cases which appear to be 
important, but which turn ut to be rather rare. For example, cases in which the 
root of a word changes with the addition of a suffix, as in DECEIVE/DECEPTION, 
RESUME/RESUMPTION, INDEX/INDICES occur much more rarely in real vocabularies 
than one might at first suppose. In view of the error rate that must in any case 
be expected, it did not seem worthwhile to try and cope with these cases. 
<P>It is not obvious that the simplicity of the present program is any demerit. 
In a test on the well-known Cranfield 200 collection<SUP>7</SUP> it gave an 
improvement in retrieval performance when compared with a very much more 
elaborate program which has been in use in IR research in Cambridge since 
1971<SUP>(2,6)</SUP>. The test was done as follows: the words of the titles and 
abstracts in the documents were passed through the earlier suffix stripping 
system, and the resultis stems were used to index the documents. The words of 
the queries were reduced to stems in the same way, and the documents were ranked 
for each query using term coordination matching of query against document. From 
these rankings, recall and precision values were obtained using the standard 
recall cutoff method. The entire process was then repeated using the suffix 
stripping system described in this paper, and the results were as follows: <PRE>        earlier system        present system
        --------------        --------------
      precision  recall     precision  recall
           0      57.24          0      58.60
          10      56.85         10      58.13
          20      52.85         20      53.92
          30      42.61         30      43.51
          40      42.20         40      39.39
          50      39.06         50      38.85
          60      32.86         60      33.18
          70      31.64         70      31.19
          80      27.15         80      27.52
          90      24.59         90      25.85
         100      24.59        100      25.85
</PRE>Cleary, the performance is not very different. The important point is that 
the earlier, more elaborate system certainly performs no better than the 
present, simple system. 
<P>(This test was done by prof. C.J. van Rijsbergen.) 
<P>
<H2>2. The Algorithm</H2>To present the suffix stripping algorithm in its 
entirety we will need a few difinitions. 
<P>A <I>consonant</I> in a word is a letter other than A, E, I, O or U, and 
other than Y preceded by a consonant. (The fact that the term `consonant' is 
defined to some extent in terms of itself does not make it ambiguous.) So in TOY 
the consonants are T and Y, and in SYZYGY they are S, Z and G. If a letter is 
not a consonant it is a <I>vowel</I>. 
<P>A consonant will be denoted by c, a vowel by v. A list ccc... of length 
greater than 0 will be denoted by C, and a list vvv... of length greater than 0 
will be denoted by V. Any word, or part of a word, therefore has one of the four 
forms: <PRE>    CVCV ... C
    CVCV ... V
    VCVC ... C
    VCVC ... V
</PRE>These may all be represented by the single form <PRE>    [C]VCVC ... [V]
</PRE>where the square brackets denote arbitrary presence of their contents. 
Using (VC)<SUP>m</SUP> to denote VC repeated m times, this may again be written 
as <PRE>    [C](VC)<SUP>m</SUP>[V].
</PRE>m will be called the <I>measure</I> of any word or word part when 
represented in this form. The case m = 0 covers the null word. Here are some 
examples: <PRE>    m=0    TR,  EE,  TREE,  Y,  BY.
    m=1    TROUBLE,  OATS,  TREES,  IVY.
    m=2    TROUBLES,  PRIVATE,  OATEN,  ORRERY.
</PRE>The <I>rules</I> for removing a suffix will be given in the form <PRE>    (condition) S1 -&gt; S2
</PRE>This means that if a word ends with the suffix S1, and the stem before S1 
satisfies the given condition, S1 is replaced by S2. The condition is usually 
given in terms of m, e.g. <PRE>    (m &gt; 1) EMENT -&gt;
</PRE>Here S1 is `EMENT' and S2 is null. This would map REPLACEMENT to REPLAC, 
since REPLAC is a word part for which m = 2. 
<P>The `condition' part may also contain the following: 
<P>*S - the stem ends with S (and similarly for the other letters). 
<P>*v* - the stem contains a vowel. 
<P>*d - the stem ends with a double consonant (e.g. -TT, -SS). 
<P>*o - the stem ends cvc, where the second c is not W, X or Y (e.g. -WIL, 
-HOP). 
<P>And the condition part may also contain expressions with <I>and</I>, 
<I>or</I> and <I>not</I>, so that <PRE>    (m&gt;1 and (*S or *T))
</PRE>tests for a stem with m&gt;1 ending in S or T, while <PRE>    (*d and not (*L or *S or *Z))
</PRE>tests for a stem ending witha double consonant other than L, S or Z. 
Elaborate conditions like this are required only rarely. 
<P>In a set of rules written beneath each other, only one is obeyed, and this 
will be the one with the longest matching S1 for the given word. For example, 
with <PRE>    SSES -&gt; SS
    IES  -&gt; I
    SS   -&gt; SS
    S    -&gt;
</PRE>(here the conditions are all null) CARESSES maps to CARESS since SSES is 
the longest match for S1. Equally CARESS maps to CARESS (S1=`SS') and CARES to 
CARE (S1=`S'). 
<P>In the rules below, examples of their application, successful or otherwise, 
are given on the right in lower case. The algorithm now follows: 
<P>
<H3>Step 1a</H3><PRE>    SSES -&gt; SS                         caresses  -&gt;  caress
    IES  -&gt; I                          ponies    -&gt;  poni
                                       ties      -&gt;  ti
    SS   -&gt; SS                         caress    -&gt;  caress
    S    -&gt;                            cats      -&gt;  cat
</PRE>
<H3>Step 1b</H3><PRE>    (m&gt;0) EED -&gt; EE                    feed      -&gt;  feed
                                       agreed    -&gt;  agree
    (*v*) ED  -&gt;                       plastered -&gt;  plaster
                                       bled      -&gt;  bled
    (*v*) ING -&gt;                       motoring  -&gt;  motor
                                       sing      -&gt;  sing
</PRE>If the second or third of the rules in Step 1b is successful, the 
following is done: <PRE>    AT -&gt; ATE                       conflat(ed)  -&gt;  conflate
    BL -&gt; BLE                       troubl(ed)   -&gt;  trouble
    IZ -&gt; IZE                       siz(ed)      -&gt;  size
    (*d and not (*L or *S or *Z))
       -&gt; single letter
                                    hopp(ing)    -&gt;  hop
                                    tann(ed)     -&gt;  tan
                                    fall(ing)    -&gt;  fall
                                    hiss(ing)    -&gt;  hiss
                                    fizz(ed)     -&gt;  fizz
    (m=1 and *o) -&gt; E               fail(ing)    -&gt;  fail
                                    fil(ing)     -&gt;  file
</PRE>The rule to map to a single letter causes the removal of one of the double 
letter pair. The -E is put back on -AT, -BL and -IZ, so that the suffixes -ATE, 
-BLE and -IZE can be recognised later. This E may be removed in step 4. 
<P>
<H3>Step 1c</H3><PRE>    (*v*) Y -&gt; I                    happy        -&gt;  happi
                                    sky          -&gt;  sky
</PRE>Step 1 deals with plurals and past participles. The subsequent steps are 
much more straightforward. 
<P>
<H3>Step 2</H3><PRE>    (m&gt;0) ATIONAL -&gt;  ATE           relational     -&gt;  relate
    (m&gt;0) TIONAL  -&gt;  TION          conditional    -&gt;  condition
                                    rational       -&gt;  rational
    (m&gt;0) ENCI    -&gt;  ENCE          valenci        -&gt;  valence
    (m&gt;0) ANCI    -&gt;  ANCE          hesitanci      -&gt;  hesitance
    (m&gt;0) IZER    -&gt;  IZE           digitizer      -&gt;  digitize
    (m&gt;0) ABLI    -&gt;  ABLE          conformabli    -&gt;  conformable
    (m&gt;0) ALLI    -&gt;  AL            radicalli      -&gt;  radical
    (m&gt;0) ENTLI   -&gt;  ENT           differentli    -&gt;  different
    (m&gt;0) ELI     -&gt;  E             vileli        - &gt;  vile
    (m&gt;0) OUSLI   -&gt;  OUS           analogousli    -&gt;  analogous
    (m&gt;0) IZATION -&gt;  IZE           vietnamization -&gt;  vietnamize
    (m&gt;0) ATION   -&gt;  ATE           predication    -&gt;  predicate
    (m&gt;0) ATOR    -&gt;  ATE           operator       -&gt;  operate
    (m&gt;0) ALISM   -&gt;  AL            feudalism      -&gt;  feudal
    (m&gt;0) IVENESS -&gt;  IVE           decisiveness   -&gt;  decisive
    (m&gt;0) FULNESS -&gt;  FUL           hopefulness    -&gt;  hopeful
    (m&gt;0) OUSNESS -&gt;  OUS           callousness    -&gt;  callous
    (m&gt;0) ALITI   -&gt;  AL            formaliti      -&gt;  formal
    (m&gt;0) IVITI   -&gt;  IVE           sensitiviti    -&gt;  sensitive
    (m&gt;0) BILITI  -&gt;  BLE           sensibiliti    -&gt;  sensible
</PRE>The test for the string S1 can be made fast by doing a program switch on 
the penultimate letter of the word being tested. This gives a fairly even 
breakdown of the possible values of the string S1. It will be seen in fact that 
the S1-strings in step 2 are presented here in the alphabetical order of their 
penultimate letter. Similar techniques may be applied in the other steps. 
<P>
<H3>Step 3</H3><PRE>    (m&gt;0) ICATE -&gt;  IC              triplicate     -&gt;  triplic
    (m&gt;0) ATIVE -&gt;                  formative      -&gt;  form
    (m&gt;0) ALIZE -&gt;  AL              formalize      -&gt;  formal
    (m&gt;0) ICITI -&gt;  IC              electriciti    -&gt;  electric
    (m&gt;0) ICAL  -&gt;  IC              electrical     -&gt;  electric
    (m&gt;0) FUL   -&gt;                  hopeful        -&gt;  hope
    (m&gt;0) NESS  -&gt;                  goodness       -&gt;  good
</PRE>
<H3>Step 4</H3><PRE>    (m&gt;1) AL    -&gt;                  revival        -&gt;  reviv
    (m&gt;1) ANCE  -&gt;                  allowance      -&gt;  allow
    (m&gt;1) ENCE  -&gt;                  inference      -&gt;  infer
    (m&gt;1) ER    -&gt;                  airliner       -&gt;  airlin
    (m&gt;1) IC    -&gt;                  gyroscopic     -&gt;  gyroscop
    (m&gt;1) ABLE  -&gt;                  adjustable     -&gt;  adjust
    (m&gt;1) IBLE  -&gt;                  defensible     -&gt;  defens
    (m&gt;1) ANT   -&gt;                  irritant       -&gt;  irrit
    (m&gt;1) EMENT -&gt;                  replacement    -&gt;  replac
    (m&gt;1) MENT  -&gt;                  adjustment     -&gt;  adjust
    (m&gt;1) ENT   -&gt;                  dependent      -&gt;  depend
    (m&gt;1 and (*S or *T)) ION -&gt;     adoption       -&gt;  adopt
    (m&gt;1) OU    -&gt;                  homologou      -&gt;  homolog
    (m&gt;1) ISM   -&gt;                  communism      -&gt;  commun
    (m&gt;1) ATE   -&gt;                  activate       -&gt;  activ
    (m&gt;1) ITI   -&gt;                  angulariti     -&gt;  angular
    (m&gt;1) OUS   -&gt;                  homologous     -&gt;  homolog
    (m&gt;1) IVE   -&gt;                  effective      -&gt;  effect
    (m&gt;1) IZE   -&gt;                  bowdlerize     -&gt;  bowdler
</PRE>The suffixes are now removed. All that remains is a little tidying up. 
<P>
<H3>Step 5a</H3><PRE>    (m&gt;1) E     -&gt;                  probate        -&gt;  probat
                                    rate           -&gt;  rate
    (m=1 and not *o) E -&gt;           cease          -&gt;  ceas
</PRE>
<H3>Step 5b</H3><PRE>    (m &gt; 1 and *d and *L) -&gt; single letter
                                    controll       -&gt;  control
                                    roll           -&gt;  roll
</PRE>
<P>The algorithm is careful not to remove a suffix when the stem is too short, 
the length of the stem being given by its measure, m. There is no linguistic 
basis for this approach. It was merely observed that m could be used quite 
effectively to help decide whether or not it was wise to take off a suffix. For 
example, in the following two lists: <PRE>                  list A        list B
                  ------        ------
                  RELATE        DERIVATE
                  PROBATE       ACTIVATE
                  CONFLATE      DEMONSTRATE
                  PIRATE        NECESSITATE
                  PRELATE       RENOVATE
</PRE>-ATE is removed from the list B words, but not from the list A words. This 
means that the pairs DERIVATE/DERIVE, ACTIVATE/ACTIVE, DEMONSTRATE/DEMONS- 
TRABLE, NECESSITATE/NECESSITOUS, will conflate together. The fact that no 
attempt is made to identify prefixes can make the results look rather 
inconsistent. Thus PRELATE does not lose the -ATE, but ARCHPRELATE becomes 
ARCHPREL. In practice this does not matter too much, because the presence of the 
prefix decreases the probability of an erroneous conflation. 
<P>Complex suffixes are removed bit by bit in the different steps. Thus 
GENERALIZATIONS is stripped to GENERALIZATION (Step 1), then to GENERALIZE (Step 
2), then to GENERAL (Step 3), and then to GENER (Step 4). OSCILLATORS is 
stripped to OSCILLATOR (Step 1), then to OSCILLATE (Step 2), then to OSCILL 
(Step 4), and then to OSCIL (Step 5). In a vocabulary of 10,000 words, the 
reduction in size of the stem was distributed among the steps as follows: <PRE>    Suffix stripping of a vocabulary of 10,000 words
    ------------------------------------------------
    Number of words reduced in step 1:   3597
                  "                 2:    766
                  "                 3:    327
                  "                 4:   2424
                  "                 5:   1373
    Number of words not reduced:         3650
</PRE>The resulting vocabulary of stems contained 6370 distinct entries. Thus 
the suffix stripping process reduced the size of the vocabulary by about one 
third. 
<P>
<H2>References</H2>1. LOVINS, J.B. Development of a Stemming Algorithm. 
<I>Mechanical Translation and computation Linguistics</I>. <B>11</B> (1) March 
1968 pp 23-31. 
<P>2. ANDREWS, K. The Development of a Fast Conflation Algorithm for English. 
<I>Dissertation for the Diploma in Computer Science</I>, Computer Laboratory, 
University of Cambridge, 1971. 
<P>3. PETRARCA, A.E. and LAY W.M. Use of an automatically generated authority 
list to eliminate scattering caused by some singular and plural main index 
terms. <I>Proceedings of the American Society for Information Science</I>, 
<B>6</B> 1969 pp 277-282. 
<P>4. DATTOLA, Robert T. <I>FIRST: Flexible Information Retrieval System for 
Text</I>. Webster N.Y: Xerox Corporation, 12 Dec 1975. 
<P>5. COLOMBO, D.S. and NIEHOFF R.T. <I>Final report on improved access to 
scientific and technical information through automated vocabulary switching.</I> 
NSF Grant No. SIS75-12924 to the National Science Foundation. 
<P>6. DAWSON, J.L. Suffix Removal and Word Conflation. <I>ALLC Bulletin</I>, 
Michaelmas 1974 p.33-46. 
<P>7. CLEVERDON, C.W., MILLS J. and KEEN M. <I>Factors Determining the 
Performance of Indexing Systems</I> 2 vols. College of Aeronautics, Cranfield 
1966. 
<P>
<HR>
